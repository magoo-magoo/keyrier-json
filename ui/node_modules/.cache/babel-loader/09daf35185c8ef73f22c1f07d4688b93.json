{"ast":null,"code":"var __extends = this && this.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\n    };\n\n    return extendStatics(d, b);\n  };\n\n  return function (d, b) {\n    extendStatics(d, b);\n\n    function __() {\n      this.constructor = d;\n    }\n\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\n\nimport { BaseRegExpVisitor } from \"regexp-to-ast\";\nimport { Lexer, LexerDefinitionErrorType } from \"./lexer_public\";\nimport { compact, contains, defaults, difference, filter, find, first, flatten, forEach, has, indexOf, isArray, isEmpty, isFunction, isRegExp, isString, isUndefined, keys, map, mapValues, packArray, PRINT_ERROR, reduce, reject } from \"../utils/utils\";\nimport { canMatchCharCode, failedOptimizationPrefixMsg, getOptimizedStartCodesIndices } from \"./reg_exp\";\nimport { getRegExpAst } from \"./reg_exp_parser\";\nvar PATTERN = \"PATTERN\";\nexport var DEFAULT_MODE = \"defaultMode\";\nexport var MODES = \"modes\";\nexport var SUPPORT_STICKY = typeof new RegExp(\"(?:)\").sticky === \"boolean\";\nexport function disableSticky() {\n  SUPPORT_STICKY = false;\n}\nexport function enableSticky() {\n  SUPPORT_STICKY = true;\n}\nexport function analyzeTokenTypes(tokenTypes, options) {\n  options = defaults(options, {\n    useSticky: SUPPORT_STICKY,\n    debug: false,\n    safeMode: false,\n    positionTracking: \"full\",\n    lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n    tracer: function (msg, action) {\n      return action();\n    }\n  });\n  var tracer = options.tracer;\n  tracer(\"initCharCodeToOptimizedIndexMap\", function () {\n    initCharCodeToOptimizedIndexMap();\n  });\n  var onlyRelevantTypes;\n  tracer(\"Reject Lexer.NA\", function () {\n    onlyRelevantTypes = reject(tokenTypes, function (currType) {\n      return currType[PATTERN] === Lexer.NA;\n    });\n  });\n  var hasCustom = false;\n  var allTransformedPatterns;\n  tracer(\"Transform Patterns\", function () {\n    hasCustom = false;\n    allTransformedPatterns = map(onlyRelevantTypes, function (currType) {\n      var currPattern = currType[PATTERN];\n      /* istanbul ignore else */\n\n      if (isRegExp(currPattern)) {\n        var regExpSource = currPattern.source;\n\n        if (regExpSource.length === 1 && // only these regExp meta characters which can appear in a length one regExp\n        regExpSource !== \"^\" && regExpSource !== \"$\" && regExpSource !== \".\" && !currPattern.ignoreCase) {\n          return regExpSource;\n        } else if (regExpSource.length === 2 && regExpSource[0] === \"\\\\\" && // not a meta character\n        !contains([\"d\", \"D\", \"s\", \"S\", \"t\", \"r\", \"n\", \"t\", \"0\", \"c\", \"b\", \"B\", \"f\", \"v\", \"w\", \"W\"], regExpSource[1])) {\n          // escaped meta Characters: /\\+/ /\\[/\n          // or redundant escaping: /\\a/\n          // without the escaping \"\\\"\n          return regExpSource[1];\n        } else {\n          return options.useSticky ? addStickyFlag(currPattern) : addStartOfInput(currPattern);\n        }\n      } else if (isFunction(currPattern)) {\n        hasCustom = true; // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n\n        return {\n          exec: currPattern\n        };\n      } else if (has(currPattern, \"exec\")) {\n        hasCustom = true; // ICustomPattern\n\n        return currPattern;\n      } else if (typeof currPattern === \"string\") {\n        if (currPattern.length === 1) {\n          return currPattern;\n        } else {\n          var escapedRegExpString = currPattern.replace(/[\\\\^$.*+?()[\\]{}|]/g, \"\\\\$&\");\n          var wrappedRegExp = new RegExp(escapedRegExpString);\n          return options.useSticky ? addStickyFlag(wrappedRegExp) : addStartOfInput(wrappedRegExp);\n        }\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n  });\n  var patternIdxToType;\n  var patternIdxToGroup;\n  var patternIdxToLongerAltIdx;\n  var patternIdxToPushMode;\n  var patternIdxToPopMode;\n  tracer(\"misc mapping\", function () {\n    patternIdxToType = map(onlyRelevantTypes, function (currType) {\n      return currType.tokenTypeIdx;\n    });\n    patternIdxToGroup = map(onlyRelevantTypes, function (clazz) {\n      var groupName = clazz.GROUP;\n      /* istanbul ignore next */\n\n      if (groupName === Lexer.SKIPPED) {\n        return undefined;\n      } else if (isString(groupName)) {\n        return groupName;\n      } else if (isUndefined(groupName)) {\n        return false;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n    patternIdxToLongerAltIdx = map(onlyRelevantTypes, function (clazz) {\n      var longerAltType = clazz.LONGER_ALT;\n\n      if (longerAltType) {\n        var longerAltIdx = indexOf(onlyRelevantTypes, longerAltType);\n        return longerAltIdx;\n      }\n    });\n    patternIdxToPushMode = map(onlyRelevantTypes, function (clazz) {\n      return clazz.PUSH_MODE;\n    });\n    patternIdxToPopMode = map(onlyRelevantTypes, function (clazz) {\n      return has(clazz, \"POP_MODE\");\n    });\n  });\n  var patternIdxToCanLineTerminator;\n  tracer(\"Line Terminator Handling\", function () {\n    var lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\n    patternIdxToCanLineTerminator = map(onlyRelevantTypes, function (tokType) {\n      return false;\n    });\n\n    if (options.positionTracking !== \"onlyOffset\") {\n      patternIdxToCanLineTerminator = map(onlyRelevantTypes, function (tokType) {\n        if (has(tokType, \"LINE_BREAKS\")) {\n          return tokType.LINE_BREAKS;\n        } else {\n          if (checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false) {\n            return canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n          }\n        }\n      });\n    }\n  });\n  var patternIdxToIsCustom;\n  var patternIdxToShort;\n  var emptyGroups;\n  var patternIdxToConfig;\n  tracer(\"Misc Mapping #2\", function () {\n    patternIdxToIsCustom = map(onlyRelevantTypes, isCustomPattern);\n    patternIdxToShort = map(allTransformedPatterns, isShortPattern);\n    emptyGroups = reduce(onlyRelevantTypes, function (acc, clazz) {\n      var groupName = clazz.GROUP;\n\n      if (isString(groupName) && !(groupName === Lexer.SKIPPED)) {\n        acc[groupName] = [];\n      }\n\n      return acc;\n    }, {});\n    patternIdxToConfig = map(allTransformedPatterns, function (x, idx) {\n      return {\n        pattern: allTransformedPatterns[idx],\n        longerAlt: patternIdxToLongerAltIdx[idx],\n        canLineTerminator: patternIdxToCanLineTerminator[idx],\n        isCustom: patternIdxToIsCustom[idx],\n        short: patternIdxToShort[idx],\n        group: patternIdxToGroup[idx],\n        push: patternIdxToPushMode[idx],\n        pop: patternIdxToPopMode[idx],\n        tokenTypeIdx: patternIdxToType[idx],\n        tokenType: onlyRelevantTypes[idx]\n      };\n    });\n  });\n  var canBeOptimized = true;\n  var charCodeToPatternIdxToConfig = [];\n\n  if (!options.safeMode) {\n    tracer(\"First Char Optimization\", function () {\n      charCodeToPatternIdxToConfig = reduce(onlyRelevantTypes, function (result, currTokType, idx) {\n        if (typeof currTokType.PATTERN === \"string\") {\n          var charCode = currTokType.PATTERN.charCodeAt(0);\n          var optimizedIdx = charCodeToOptimizedIndex(charCode);\n          addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n        } else if (isArray(currTokType.START_CHARS_HINT)) {\n          var lastOptimizedIdx_1;\n          forEach(currTokType.START_CHARS_HINT, function (charOrInt) {\n            var charCode = typeof charOrInt === \"string\" ? charOrInt.charCodeAt(0) : charOrInt;\n            var currOptimizedIdx = charCodeToOptimizedIndex(charCode); // Avoid adding the config multiple times\n\n            /* istanbul ignore else */\n            // - Difficult to check this scenario effects as it is only a performance\n            //   optimization that does not change correctness\n\n            if (lastOptimizedIdx_1 !== currOptimizedIdx) {\n              lastOptimizedIdx_1 = currOptimizedIdx;\n              addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\n            }\n          });\n        } else if (isRegExp(currTokType.PATTERN)) {\n          if (currTokType.PATTERN.unicode) {\n            canBeOptimized = false;\n\n            if (options.ensureOptimizations) {\n              PRINT_ERROR(\"\" + failedOptimizationPrefixMsg + (\"\\tUnable to analyze < \" + currTokType.PATTERN.toString() + \" > pattern.\\n\") + \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" + \"\\tThis will disable the lexer's first char optimizations.\\n\" + \"\\tFor details See: https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\");\n            }\n          } else {\n            var optimizedCodes = getOptimizedStartCodesIndices(currTokType.PATTERN, options.ensureOptimizations);\n            /* istanbul ignore if */\n            // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n            // the first should be a different validation and the second cannot be tested.\n\n            if (isEmpty(optimizedCodes)) {\n              // we cannot understand what codes may start possible matches\n              // The optimization correctness requires knowing start codes for ALL patterns.\n              // Not actually sure this is an error, no debug message\n              canBeOptimized = false;\n            }\n\n            forEach(optimizedCodes, function (code) {\n              addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n            });\n          }\n        } else {\n          if (options.ensureOptimizations) {\n            PRINT_ERROR(\"\" + failedOptimizationPrefixMsg + (\"\\tTokenType: <\" + currTokType.name + \"> is using a custom token pattern without providing <start_chars_hint> parameter.\\n\") + \"\\tThis will disable the lexer's first char optimizations.\\n\" + \"\\tFor details See: https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\");\n          }\n\n          canBeOptimized = false;\n        }\n\n        return result;\n      }, []);\n    });\n  }\n\n  tracer(\"ArrayPacking\", function () {\n    charCodeToPatternIdxToConfig = packArray(charCodeToPatternIdxToConfig);\n  });\n  return {\n    emptyGroups: emptyGroups,\n    patternIdxToConfig: patternIdxToConfig,\n    charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n    hasCustom: hasCustom,\n    canBeOptimized: canBeOptimized\n  };\n}\nexport function validatePatterns(tokenTypes, validModesNames) {\n  var errors = [];\n  var missingResult = findMissingPatterns(tokenTypes);\n  errors = errors.concat(missingResult.errors);\n  var invalidResult = findInvalidPatterns(missingResult.valid);\n  var validTokenTypes = invalidResult.valid;\n  errors = errors.concat(invalidResult.errors);\n  errors = errors.concat(validateRegExpPattern(validTokenTypes));\n  errors = errors.concat(findInvalidGroupType(validTokenTypes));\n  errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\n  errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n  return errors;\n}\n\nfunction validateRegExpPattern(tokenTypes) {\n  var errors = [];\n  var withRegExpPatterns = filter(tokenTypes, function (currTokType) {\n    return isRegExp(currTokType[PATTERN]);\n  });\n  errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n  errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n  errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n  errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n  errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n  return errors;\n}\n\nexport function findMissingPatterns(tokenTypes) {\n  var tokenTypesWithMissingPattern = filter(tokenTypes, function (currType) {\n    return !has(currType, PATTERN);\n  });\n  var errors = map(tokenTypesWithMissingPattern, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- missing static 'PATTERN' property\",\n      type: LexerDefinitionErrorType.MISSING_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  var valid = difference(tokenTypes, tokenTypesWithMissingPattern);\n  return {\n    errors: errors,\n    valid: valid\n  };\n}\nexport function findInvalidPatterns(tokenTypes) {\n  var tokenTypesWithInvalidPattern = filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    return !isRegExp(pattern) && !isFunction(pattern) && !has(pattern, \"exec\") && !isString(pattern);\n  });\n  var errors = map(tokenTypesWithInvalidPattern, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' can only be a RegExp, a\" + \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n      type: LexerDefinitionErrorType.INVALID_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  var valid = difference(tokenTypes, tokenTypesWithInvalidPattern);\n  return {\n    errors: errors,\n    valid: valid\n  };\n}\nvar end_of_input = /[^\\\\][\\$]/;\nexport function findEndOfInputAnchor(tokenTypes) {\n  var EndAnchorFinder =\n  /** @class */\n  function (_super) {\n    __extends(EndAnchorFinder, _super);\n\n    function EndAnchorFinder() {\n      var _this = _super !== null && _super.apply(this, arguments) || this;\n\n      _this.found = false;\n      return _this;\n    }\n\n    EndAnchorFinder.prototype.visitEndAnchor = function (node) {\n      this.found = true;\n    };\n\n    return EndAnchorFinder;\n  }(BaseRegExpVisitor);\n\n  var invalidRegex = filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n\n    try {\n      var regexpAst = getRegExpAst(pattern);\n      var endAnchorVisitor = new EndAnchorFinder();\n      endAnchorVisitor.visit(regexpAst);\n      return endAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return end_of_input.test(pattern.source);\n    }\n  });\n  var errors = map(invalidRegex, function (currType) {\n    return {\n      message: \"Unexpected RegExp Anchor Error:\\n\" + \"\\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" + \"\\tSee sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#ANCHORS\" + \"\\tfor details.\",\n      type: LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexport function findEmptyMatchRegExps(tokenTypes) {\n  var matchesEmptyString = filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    return pattern.test(\"\");\n  });\n  var errors = map(matchesEmptyString, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' must not match an empty string\",\n      type: LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nvar start_of_input = /[^\\\\[][\\^]|^\\^/;\nexport function findStartOfInputAnchor(tokenTypes) {\n  var StartAnchorFinder =\n  /** @class */\n  function (_super) {\n    __extends(StartAnchorFinder, _super);\n\n    function StartAnchorFinder() {\n      var _this = _super !== null && _super.apply(this, arguments) || this;\n\n      _this.found = false;\n      return _this;\n    }\n\n    StartAnchorFinder.prototype.visitStartAnchor = function (node) {\n      this.found = true;\n    };\n\n    return StartAnchorFinder;\n  }(BaseRegExpVisitor);\n\n  var invalidRegex = filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n\n    try {\n      var regexpAst = getRegExpAst(pattern);\n      var startAnchorVisitor = new StartAnchorFinder();\n      startAnchorVisitor.visit(regexpAst);\n      return startAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return start_of_input.test(pattern.source);\n    }\n  });\n  var errors = map(invalidRegex, function (currType) {\n    return {\n      message: \"Unexpected RegExp Anchor Error:\\n\" + \"\\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" + \"\\tSee https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#ANCHORS\" + \"\\tfor details.\",\n      type: LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexport function findUnsupportedFlags(tokenTypes) {\n  var invalidFlags = filter(tokenTypes, function (currType) {\n    var pattern = currType[PATTERN];\n    return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n  });\n  var errors = map(invalidFlags, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n      type: LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n} // This can only test for identical duplicate RegExps, not semantically equivalent ones.\n\nexport function findDuplicatePatterns(tokenTypes) {\n  var found = [];\n  var identicalPatterns = map(tokenTypes, function (outerType) {\n    return reduce(tokenTypes, function (result, innerType) {\n      if (outerType.PATTERN.source === innerType.PATTERN.source && !contains(found, innerType) && innerType.PATTERN !== Lexer.NA) {\n        // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n        // in essence we are creating Equivalence classes on equality relation.\n        found.push(innerType);\n        result.push(innerType);\n        return result;\n      }\n\n      return result;\n    }, []);\n  });\n  identicalPatterns = compact(identicalPatterns);\n  var duplicatePatterns = filter(identicalPatterns, function (currIdenticalSet) {\n    return currIdenticalSet.length > 1;\n  });\n  var errors = map(duplicatePatterns, function (setOfIdentical) {\n    var tokenTypeNames = map(setOfIdentical, function (currType) {\n      return currType.name;\n    });\n    var dupPatternSrc = first(setOfIdentical).PATTERN;\n    return {\n      message: \"The same RegExp pattern ->\" + dupPatternSrc + \"<-\" + (\"has been used in all of the following Token Types: \" + tokenTypeNames.join(\", \") + \" <-\"),\n      type: LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n      tokenTypes: setOfIdentical\n    };\n  });\n  return errors;\n}\nexport function findInvalidGroupType(tokenTypes) {\n  var invalidTypes = filter(tokenTypes, function (clazz) {\n    if (!has(clazz, \"GROUP\")) {\n      return false;\n    }\n\n    var group = clazz.GROUP;\n    return group !== Lexer.SKIPPED && group !== Lexer.NA && !isString(group);\n  });\n  var errors = map(invalidTypes, function (currType) {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n      type: LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\nexport function findModesThatDoNotExist(tokenTypes, validModes) {\n  var invalidModes = filter(tokenTypes, function (clazz) {\n    return clazz.PUSH_MODE !== undefined && !contains(validModes, clazz.PUSH_MODE);\n  });\n  var errors = map(invalidModes, function (tokType) {\n    var msg = \"Token Type: ->\" + tokType.name + \"<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->\" + tokType.PUSH_MODE + \"<-\" + \"which does not exist\";\n    return {\n      message: msg,\n      type: LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n      tokenTypes: [tokType]\n    };\n  });\n  return errors;\n}\nexport function findUnreachablePatterns(tokenTypes) {\n  var errors = [];\n  var canBeTested = reduce(tokenTypes, function (result, tokType, idx) {\n    var pattern = tokType.PATTERN;\n\n    if (pattern === Lexer.NA) {\n      return result;\n    } // a more comprehensive validation for all forms of regExps would require\n    // deeper regExp analysis capabilities\n\n\n    if (isString(pattern)) {\n      result.push({\n        str: pattern,\n        idx: idx,\n        tokenType: tokType\n      });\n    } else if (isRegExp(pattern) && noMetaChar(pattern)) {\n      result.push({\n        str: pattern.source,\n        idx: idx,\n        tokenType: tokType\n      });\n    }\n\n    return result;\n  }, []);\n  forEach(tokenTypes, function (tokType, testIdx) {\n    forEach(canBeTested, function (_a) {\n      var str = _a.str,\n          idx = _a.idx,\n          tokenType = _a.tokenType;\n\n      if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n        var msg = \"Token: ->\" + tokenType.name + \"<- can never be matched.\\n\" + (\"Because it appears AFTER the Token Type ->\" + tokType.name + \"<-\") + \"in the lexer's definition.\\n\" + \"See https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#UNREACHABLE\";\n        errors.push({\n          message: msg,\n          type: LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n          tokenTypes: [tokType, tokenType]\n        });\n      }\n    });\n  });\n  return errors;\n}\n\nfunction testTokenType(str, pattern) {\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    var regExpArray = pattern.exec(str);\n    return regExpArray !== null && regExpArray.index === 0;\n  } else if (isFunction(pattern)) {\n    // maintain the API of custom patterns\n    return pattern(str, 0, [], {});\n  } else if (has(pattern, \"exec\")) {\n    // maintain the API of custom patterns\n    return pattern.exec(str, 0, [], {});\n  } else if (typeof pattern === \"string\") {\n    return pattern === str;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nfunction noMetaChar(regExp) {\n  //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n  var metaChars = [\".\", \"\\\\\", \"[\", \"]\", \"|\", \"^\", \"$\", \"(\", \")\", \"?\", \"*\", \"+\", \"{\"];\n  return find(metaChars, function (char) {\n    return regExp.source.indexOf(char) !== -1;\n  }) === undefined;\n}\n\nexport function addStartOfInput(pattern) {\n  var flags = pattern.ignoreCase ? \"i\" : \"\"; // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n\n  return new RegExp(\"^(?:\" + pattern.source + \")\", flags);\n}\nexport function addStickyFlag(pattern) {\n  var flags = pattern.ignoreCase ? \"iy\" : \"y\"; // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n\n  return new RegExp(\"\" + pattern.source, flags);\n}\nexport function performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n  var errors = []; // some run time checks to help the end users.\n\n  if (!has(lexerDefinition, DEFAULT_MODE)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized without a <\" + DEFAULT_MODE + \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n    });\n  }\n\n  if (!has(lexerDefinition, MODES)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized without a <\" + MODES + \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n    });\n  }\n\n  if (has(lexerDefinition, MODES) && has(lexerDefinition, DEFAULT_MODE) && !has(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized with a \" + DEFAULT_MODE + \": <\" + lexerDefinition.defaultMode + \">\" + \"which does not exist\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n    });\n  }\n\n  if (has(lexerDefinition, MODES)) {\n    forEach(lexerDefinition.modes, function (currModeValue, currModeName) {\n      forEach(currModeValue, function (currTokType, currIdx) {\n        if (isUndefined(currTokType)) {\n          errors.push({\n            message: \"A Lexer cannot be initialized using an undefined Token Type. Mode:\" + (\"<\" + currModeName + \"> at index: <\" + currIdx + \">\\n\"),\n            type: LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n          });\n        }\n      });\n    });\n  }\n\n  return errors;\n}\nexport function performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n  var warnings = [];\n  var hasAnyLineBreak = false;\n  var allTokenTypes = compact(flatten(mapValues(lexerDefinition.modes, function (tokTypes) {\n    return tokTypes;\n  })));\n  var concreteTokenTypes = reject(allTokenTypes, function (currType) {\n    return currType[PATTERN] === Lexer.NA;\n  });\n  var terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n\n  if (trackLines) {\n    forEach(concreteTokenTypes, function (tokType) {\n      var currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n\n      if (currIssue !== false) {\n        var message = buildLineBreakIssueMessage(tokType, currIssue);\n        var warningDescriptor = {\n          message: message,\n          type: currIssue.issue,\n          tokenType: tokType\n        };\n        warnings.push(warningDescriptor);\n      } else {\n        // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n        if (has(tokType, \"LINE_BREAKS\")) {\n          if (tokType.LINE_BREAKS === true) {\n            hasAnyLineBreak = true;\n          }\n        } else {\n          if (canMatchCharCode(terminatorCharCodes, tokType.PATTERN)) {\n            hasAnyLineBreak = true;\n          }\n        }\n      }\n    });\n  }\n\n  if (trackLines && !hasAnyLineBreak) {\n    warnings.push({\n      message: \"Warning: No LINE_BREAKS Found.\\n\" + \"\\tThis Lexer has been defined to track line and column information,\\n\" + \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" + \"\\tSee https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" + \"\\tfor details.\",\n      type: LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\n    });\n  }\n\n  return warnings;\n}\nexport function cloneEmptyGroups(emptyGroups) {\n  var clonedResult = {};\n  var groupKeys = keys(emptyGroups);\n  forEach(groupKeys, function (currKey) {\n    var currGroupValue = emptyGroups[currKey];\n    /* istanbul ignore else */\n\n    if (isArray(currGroupValue)) {\n      clonedResult[currKey] = [];\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  });\n  return clonedResult;\n} // TODO: refactor to avoid duplication\n\nexport function isCustomPattern(tokenType) {\n  var pattern = tokenType.PATTERN;\n  /* istanbul ignore else */\n\n  if (isRegExp(pattern)) {\n    return false;\n  } else if (isFunction(pattern)) {\n    // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n    return true;\n  } else if (has(pattern, \"exec\")) {\n    // ICustomPattern\n    return true;\n  } else if (isString(pattern)) {\n    return false;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\nexport function isShortPattern(pattern) {\n  if (isString(pattern) && pattern.length === 1) {\n    return pattern.charCodeAt(0);\n  } else {\n    return false;\n  }\n}\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\n\nexport var LineTerminatorOptimizedTester = {\n  // implements /\\n|\\r\\n?/g.test\n  test: function (text) {\n    var len = text.length;\n\n    for (var i = this.lastIndex; i < len; i++) {\n      var c = text.charCodeAt(i);\n\n      if (c === 10) {\n        this.lastIndex = i + 1;\n        return true;\n      } else if (c === 13) {\n        if (text.charCodeAt(i + 1) === 10) {\n          this.lastIndex = i + 2;\n        } else {\n          this.lastIndex = i + 1;\n        }\n\n        return true;\n      }\n    }\n\n    return false;\n  },\n  lastIndex: 0\n};\n\nfunction checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\n  if (has(tokType, \"LINE_BREAKS\")) {\n    // if the user explicitly declared the line_breaks option we will respect their choice\n    // and assume it is correct.\n    return false;\n  } else {\n    /* istanbul ignore else */\n    if (isRegExp(tokType.PATTERN)) {\n      try {\n        canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n      } catch (e) {\n        /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n        return {\n          issue: LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n          errMsg: e.message\n        };\n      }\n\n      return false;\n    } else if (isString(tokType.PATTERN)) {\n      // string literal patterns can always be analyzed to detect line terminator usage\n      return false;\n    } else if (isCustomPattern(tokType)) {\n      // custom token types\n      return {\n        issue: LexerDefinitionErrorType.CUSTOM_LINE_BREAK\n      };\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n}\n\nexport function buildLineBreakIssueMessage(tokType, details) {\n  /* istanbul ignore else */\n  if (details.issue === LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n    return \"Warning: unable to identify line terminator usage in pattern.\\n\" + (\"\\tThe problem is in the <\" + tokType.name + \"> Token Type\\n\") + (\"\\t Root cause: \" + details.errMsg + \".\\n\") + \"\\tFor details See: https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\";\n  } else if (details.issue === LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n    return \"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" + (\"\\tThe problem is in the <\" + tokType.name + \"> Token Type\\n\") + \"\\tFor details See: https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\";\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nfunction getCharCodes(charsOrCodes) {\n  var charCodes = map(charsOrCodes, function (numOrString) {\n    if (isString(numOrString) && numOrString.length > 0) {\n      return numOrString.charCodeAt(0);\n    } else {\n      return numOrString;\n    }\n  });\n  return charCodes;\n}\n\nfunction addToMapOfArrays(map, key, value) {\n  if (map[key] === undefined) {\n    map[key] = [value];\n  } else {\n    map[key].push(value);\n  }\n}\n\nexport var minOptimizationVal = 256;\n/**\n * We ae mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\n\nexport function charCodeToOptimizedIndex(charCode) {\n  return charCode < minOptimizationVal ? charCode : charCodeToOptimizedIdxMap[charCode];\n}\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\n\nvar charCodeToOptimizedIdxMap = [];\n\nfunction initCharCodeToOptimizedIndexMap() {\n  if (isEmpty(charCodeToOptimizedIdxMap)) {\n    charCodeToOptimizedIdxMap = new Array(65536);\n\n    for (var i = 0; i < 65536; i++) {\n      /* tslint:disable */\n      charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n      /* tslint:enable */\n    }\n  }\n}","map":{"version":3,"sources":["../../../src/scan/lexer.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;AAAA,SAAS,iBAAT,QAAkC,eAAlC;AACA,SAAsB,KAAtB,EAA6B,wBAA7B,QAA6D,gBAA7D;AACA,SACE,OADF,EAEE,QAFF,EAGE,QAHF,EAIE,UAJF,EAKE,MALF,EAME,IANF,EAOE,KAPF,EAQE,OARF,EASE,OATF,EAUE,GAVF,EAWE,OAXF,EAYE,OAZF,EAaE,OAbF,EAcE,UAdF,EAeE,QAfF,EAgBE,QAhBF,EAiBE,WAjBF,EAkBE,IAlBF,EAmBE,GAnBF,EAoBE,SApBF,EAqBE,SArBF,EAsBE,WAtBF,EAuBE,MAvBF,EAwBE,MAxBF,QAyBO,gBAzBP;AA0BA,SACE,gBADF,EAEE,2BAFF,EAGE,6BAHF,QAIO,WAJP;AAYA,SAAS,YAAT,QAA6B,kBAA7B;AAEA,IAAM,OAAO,GAAG,SAAhB;AACA,OAAO,IAAM,YAAY,GAAG,aAArB;AACP,OAAO,IAAM,KAAK,GAAG,OAAd;AAsBP,OAAO,IAAI,cAAc,GACvB,OAAa,IAAI,MAAJ,CAAW,MAAX,EAAoB,MAAjC,KAA4C,SADvC;AAGP,OAAM,SAAU,aAAV,GAAuB;AAC3B,EAAA,cAAc,GAAG,KAAjB;AACD;AAED,OAAM,SAAU,YAAV,GAAsB;AAC1B,EAAA,cAAc,GAAG,IAAjB;AACD;AAED,OAAM,SAAU,iBAAV,CACJ,UADI,EAEJ,OAFI,EAUH;AAED,EAAA,OAAO,GAAG,QAAQ,CAAC,OAAD,EAAU;AAC1B,IAAA,SAAS,EAAE,cADe;AAE1B,IAAA,KAAK,EAAE,KAFmB;AAG1B,IAAA,QAAQ,EAAE,KAHgB;AAI1B,IAAA,gBAAgB,EAAE,MAJQ;AAK1B,IAAA,wBAAwB,EAAE,CAAC,IAAD,EAAO,IAAP,CALA;AAM1B,IAAA,MAAM,EAAE,UAAC,GAAD,EAAM,MAAN,EAAY;AAAK,aAAA,MAAA,EAAA;AAAQ;AANP,GAAV,CAAlB;AASA,MAAM,MAAM,GAAG,OAAO,CAAC,MAAvB;AAEA,EAAA,MAAM,CAAC,iCAAD,EAAoC,YAAA;AACxC,IAAA,+BAA+B;AAChC,GAFK,CAAN;AAIA,MAAI,iBAAJ;AACA,EAAA,MAAM,CAAC,iBAAD,EAAoB,YAAA;AACxB,IAAA,iBAAiB,GAAG,MAAM,CAAC,UAAD,EAAa,UAAC,QAAD,EAAS;AAC9C,aAAO,QAAQ,CAAC,OAAD,CAAR,KAAsB,KAAK,CAAC,EAAnC;AACD,KAFyB,CAA1B;AAGD,GAJK,CAAN;AAMA,MAAI,SAAS,GAAG,KAAhB;AACA,MAAI,sBAAJ;AACA,EAAA,MAAM,CAAC,oBAAD,EAAuB,YAAA;AAC3B,IAAA,SAAS,GAAG,KAAZ;AACA,IAAA,sBAAsB,GAAG,GAAG,CAAC,iBAAD,EAAoB,UAAC,QAAD,EAAS;AACvD,UAAI,WAAW,GAAG,QAAQ,CAAC,OAAD,CAA1B;AAEA;;AACA,UAAI,QAAQ,CAAC,WAAD,CAAZ,EAA2B;AACzB,YAAI,YAAY,GAAG,WAAW,CAAC,MAA/B;;AACA,YACE,YAAY,CAAC,MAAb,KAAwB,CAAxB,IACA;AACA,QAAA,YAAY,KAAK,GAFjB,IAGA,YAAY,KAAK,GAHjB,IAIA,YAAY,KAAK,GAJjB,IAKA,CAAC,WAAW,CAAC,UANf,EAOE;AACA,iBAAO,YAAP;AACD,SATD,MASO,IACL,YAAY,CAAC,MAAb,KAAwB,CAAxB,IACA,YAAY,CAAC,CAAD,CAAZ,KAAoB,IADpB,IAEA;AACA,SAAC,QAAQ,CACP,CACE,GADF,EAEE,GAFF,EAGE,GAHF,EAIE,GAJF,EAKE,GALF,EAME,GANF,EAOE,GAPF,EAQE,GARF,EASE,GATF,EAUE,GAVF,EAWE,GAXF,EAYE,GAZF,EAaE,GAbF,EAcE,GAdF,EAeE,GAfF,EAgBE,GAhBF,CADO,EAmBP,YAAY,CAAC,CAAD,CAnBL,CAJJ,EAyBL;AACA;AACA;AACA;AACA,iBAAO,YAAY,CAAC,CAAD,CAAnB;AACD,SA9BM,MA8BA;AACL,iBAAO,OAAO,CAAC,SAAR,GACH,aAAa,CAAC,WAAD,CADV,GAEH,eAAe,CAAC,WAAD,CAFnB;AAGD;AACF,OA9CD,MA8CO,IAAI,UAAU,CAAC,WAAD,CAAd,EAA6B;AAClC,QAAA,SAAS,GAAG,IAAZ,CADkC,CAElC;;AACA,eAAO;AAAE,UAAA,IAAI,EAAE;AAAR,SAAP;AACD,OAJM,MAIA,IAAI,GAAG,CAAC,WAAD,EAAc,MAAd,CAAP,EAA8B;AACnC,QAAA,SAAS,GAAG,IAAZ,CADmC,CAEnC;;AACA,eAAO,WAAP;AACD,OAJM,MAIA,IAAI,OAAO,WAAP,KAAuB,QAA3B,EAAqC;AAC1C,YAAI,WAAW,CAAC,MAAZ,KAAuB,CAA3B,EAA8B;AAC5B,iBAAO,WAAP;AACD,SAFD,MAEO;AACL,cAAI,mBAAmB,GAAG,WAAW,CAAC,OAAZ,CACxB,qBADwB,EAExB,MAFwB,CAA1B;AAIA,cAAI,aAAa,GAAG,IAAI,MAAJ,CAAW,mBAAX,CAApB;AACA,iBAAO,OAAO,CAAC,SAAR,GACH,aAAa,CAAC,aAAD,CADV,GAEH,eAAe,CAAC,aAAD,CAFnB;AAGD;AACF,OAbM,MAaA;AACL,cAAM,KAAK,CAAC,sBAAD,CAAX;AACD;AACF,KA1E2B,CAA5B;AA2ED,GA7EK,CAAN;AA+EA,MAAI,gBAAJ;AACA,MAAI,iBAAJ;AACA,MAAI,wBAAJ;AACA,MAAI,oBAAJ;AACA,MAAI,mBAAJ;AACA,EAAA,MAAM,CAAC,cAAD,EAAiB,YAAA;AACrB,IAAA,gBAAgB,GAAG,GAAG,CACpB,iBADoB,EAEpB,UAAC,QAAD,EAAS;AAAK,aAAA,QAAQ,CAAR,YAAA;AAAqB,KAFf,CAAtB;AAKA,IAAA,iBAAiB,GAAG,GAAG,CAAC,iBAAD,EAAoB,UAAC,KAAD,EAAW;AACpD,UAAI,SAAS,GAAG,KAAK,CAAC,KAAtB;AACA;;AACA,UAAI,SAAS,KAAK,KAAK,CAAC,OAAxB,EAAiC;AAC/B,eAAO,SAAP;AACD,OAFD,MAEO,IAAI,QAAQ,CAAC,SAAD,CAAZ,EAAyB;AAC9B,eAAO,SAAP;AACD,OAFM,MAEA,IAAI,WAAW,CAAC,SAAD,CAAf,EAA4B;AACjC,eAAO,KAAP;AACD,OAFM,MAEA;AACL,cAAM,KAAK,CAAC,sBAAD,CAAX;AACD;AACF,KAZsB,CAAvB;AAcA,IAAA,wBAAwB,GAAG,GAAG,CAAC,iBAAD,EAAoB,UAAC,KAAD,EAAW;AAC3D,UAAI,aAAa,GAAG,KAAK,CAAC,UAA1B;;AAEA,UAAI,aAAJ,EAAmB;AACjB,YAAI,YAAY,GAAG,OAAO,CAAC,iBAAD,EAAoB,aAApB,CAA1B;AACA,eAAO,YAAP;AACD;AACF,KAP6B,CAA9B;AASA,IAAA,oBAAoB,GAAG,GAAG,CACxB,iBADwB,EAExB,UAAC,KAAD,EAAW;AAAK,aAAA,KAAK,CAAL,SAAA;AAAe,KAFP,CAA1B;AAKA,IAAA,mBAAmB,GAAG,GAAG,CAAC,iBAAD,EAAoB,UAAC,KAAD,EAAW;AACtD,aAAA,GAAG,CAAC,KAAD,EAAQ,UAAR,CAAH;AAAsB,KADC,CAAzB;AAGD,GArCK,CAAN;AAuCA,MAAI,6BAAJ;AACA,EAAA,MAAM,CAAC,0BAAD,EAA6B,YAAA;AACjC,QAAM,uBAAuB,GAAG,YAAY,CAC1C,OAAO,CAAC,wBADkC,CAA5C;AAGA,IAAA,6BAA6B,GAAG,GAAG,CAAC,iBAAD,EAAoB,UAAC,OAAD,EAAQ;AAAK,aAAA,KAAA;AAAK,KAAtC,CAAnC;;AACA,QAAI,OAAO,CAAC,gBAAR,KAA6B,YAAjC,EAA+C;AAC7C,MAAA,6BAA6B,GAAG,GAAG,CAAC,iBAAD,EAAoB,UAAC,OAAD,EAAQ;AAC7D,YAAI,GAAG,CAAC,OAAD,EAAU,aAAV,CAAP,EAAiC;AAC/B,iBAAO,OAAO,CAAC,WAAf;AACD,SAFD,MAEO;AACL,cACE,qBAAqB,CAAC,OAAD,EAAU,uBAAV,CAArB,KAA4D,KAD9D,EAEE;AACA,mBAAO,gBAAgB,CAAC,uBAAD,EAA0B,OAAO,CAAC,OAAlC,CAAvB;AACD;AACF;AACF,OAVkC,CAAnC;AAWD;AACF,GAlBK,CAAN;AAoBA,MAAI,oBAAJ;AACA,MAAI,iBAAJ;AACA,MAAI,WAAJ;AACA,MAAI,kBAAJ;AACA,EAAA,MAAM,CAAC,iBAAD,EAAoB,YAAA;AACxB,IAAA,oBAAoB,GAAG,GAAG,CAAC,iBAAD,EAAoB,eAApB,CAA1B;AACA,IAAA,iBAAiB,GAAG,GAAG,CAAC,sBAAD,EAAyB,cAAzB,CAAvB;AAEA,IAAA,WAAW,GAAG,MAAM,CAClB,iBADkB,EAElB,UAAC,GAAD,EAAM,KAAN,EAAgB;AACd,UAAI,SAAS,GAAG,KAAK,CAAC,KAAtB;;AACA,UAAI,QAAQ,CAAC,SAAD,CAAR,IAAuB,EAAE,SAAS,KAAK,KAAK,CAAC,OAAtB,CAA3B,EAA2D;AACzD,QAAA,GAAG,CAAC,SAAD,CAAH,GAAiB,EAAjB;AACD;;AACD,aAAO,GAAP;AACD,KARiB,EASlB,EATkB,CAApB;AAYA,IAAA,kBAAkB,GAAG,GAAG,CAAC,sBAAD,EAAyB,UAAC,CAAD,EAAI,GAAJ,EAAO;AACtD,aAAO;AACL,QAAA,OAAO,EAAE,sBAAsB,CAAC,GAAD,CAD1B;AAEL,QAAA,SAAS,EAAE,wBAAwB,CAAC,GAAD,CAF9B;AAGL,QAAA,iBAAiB,EAAE,6BAA6B,CAAC,GAAD,CAH3C;AAIL,QAAA,QAAQ,EAAE,oBAAoB,CAAC,GAAD,CAJzB;AAKL,QAAA,KAAK,EAAE,iBAAiB,CAAC,GAAD,CALnB;AAML,QAAA,KAAK,EAAE,iBAAiB,CAAC,GAAD,CANnB;AAOL,QAAA,IAAI,EAAE,oBAAoB,CAAC,GAAD,CAPrB;AAQL,QAAA,GAAG,EAAE,mBAAmB,CAAC,GAAD,CARnB;AASL,QAAA,YAAY,EAAE,gBAAgB,CAAC,GAAD,CATzB;AAUL,QAAA,SAAS,EAAE,iBAAiB,CAAC,GAAD;AAVvB,OAAP;AAYD,KAbuB,CAAxB;AAcD,GA9BK,CAAN;AAgCA,MAAI,cAAc,GAAG,IAArB;AACA,MAAI,4BAA4B,GAAG,EAAnC;;AAEA,MAAI,CAAC,OAAO,CAAC,QAAb,EAAuB;AACrB,IAAA,MAAM,CAAC,yBAAD,EAA4B,YAAA;AAChC,MAAA,4BAA4B,GAAG,MAAM,CACnC,iBADmC,EAEnC,UAAC,MAAD,EAAS,WAAT,EAAsB,GAAtB,EAAyB;AACvB,YAAI,OAAO,WAAW,CAAC,OAAnB,KAA+B,QAAnC,EAA6C;AAC3C,cAAM,QAAQ,GAAG,WAAW,CAAC,OAAZ,CAAoB,UAApB,CAA+B,CAA/B,CAAjB;AACA,cAAM,YAAY,GAAG,wBAAwB,CAAC,QAAD,CAA7C;AACA,UAAA,gBAAgB,CAAC,MAAD,EAAS,YAAT,EAAuB,kBAAkB,CAAC,GAAD,CAAzC,CAAhB;AACD,SAJD,MAIO,IAAI,OAAO,CAAC,WAAW,CAAC,gBAAb,CAAX,EAA2C;AAChD,cAAI,kBAAJ;AACA,UAAA,OAAO,CAAC,WAAW,CAAC,gBAAb,EAA+B,UAAC,SAAD,EAAU;AAC9C,gBAAM,QAAQ,GACZ,OAAO,SAAP,KAAqB,QAArB,GACI,SAAS,CAAC,UAAV,CAAqB,CAArB,CADJ,GAEI,SAHN;AAIA,gBAAM,gBAAgB,GAAG,wBAAwB,CAAC,QAAD,CAAjD,CAL8C,CAM9C;;AACA;AACA;AACA;;AACA,gBAAI,kBAAgB,KAAK,gBAAzB,EAA2C;AACzC,cAAA,kBAAgB,GAAG,gBAAnB;AACA,cAAA,gBAAgB,CACd,MADc,EAEd,gBAFc,EAGd,kBAAkB,CAAC,GAAD,CAHJ,CAAhB;AAKD;AACF,WAlBM,CAAP;AAmBD,SArBM,MAqBA,IAAI,QAAQ,CAAC,WAAW,CAAC,OAAb,CAAZ,EAAmC;AACxC,cAAI,WAAW,CAAC,OAAZ,CAAoB,OAAxB,EAAiC;AAC/B,YAAA,cAAc,GAAG,KAAjB;;AACA,gBAAI,OAAO,CAAC,mBAAZ,EAAiC;AAC/B,cAAA,WAAW,CACT,KAAG,2BAAH,IACE,2BAAyB,WAAW,CAAC,OAAZ,CAAoB,QAApB,EAAzB,GAAuD,eADzD,IAEE,sFAFF,GAGE,6DAHF,GAIE,6GALO,CAAX;AAOD;AACF,WAXD,MAWO;AACL,gBAAI,cAAc,GAAG,6BAA6B,CAChD,WAAW,CAAC,OADoC,EAEhD,OAAO,CAAC,mBAFwC,CAAlD;AAIA;AACA;AACA;;AACA,gBAAI,OAAO,CAAC,cAAD,CAAX,EAA6B;AAC3B;AACA;AACA;AACA,cAAA,cAAc,GAAG,KAAjB;AACD;;AACD,YAAA,OAAO,CAAC,cAAD,EAAiB,UAAC,IAAD,EAAK;AAC3B,cAAA,gBAAgB,CAAC,MAAD,EAAS,IAAT,EAAe,kBAAkB,CAAC,GAAD,CAAjC,CAAhB;AACD,aAFM,CAAP;AAGD;AACF,SA9BM,MA8BA;AACL,cAAI,OAAO,CAAC,mBAAZ,EAAiC;AAC/B,YAAA,WAAW,CACT,KAAG,2BAAH,IACE,mBAAiB,WAAW,CAAC,IAA7B,GAAiC,qFADnC,IAEE,6DAFF,GAGE,4GAJO,CAAX;AAMD;;AACD,UAAA,cAAc,GAAG,KAAjB;AACD;;AAED,eAAO,MAAP;AACD,OAvEkC,EAwEnC,EAxEmC,CAArC;AA0ED,KA3EK,CAAN;AA4ED;;AACD,EAAA,MAAM,CAAC,cAAD,EAAiB,YAAA;AACrB,IAAA,4BAA4B,GAAG,SAAS,CAAC,4BAAD,CAAxC;AACD,GAFK,CAAN;AAIA,SAAO;AACL,IAAA,WAAW,EAAE,WADR;AAEL,IAAA,kBAAkB,EAAE,kBAFf;AAGL,IAAA,4BAA4B,EAAE,4BAHzB;AAIL,IAAA,SAAS,EAAE,SAJN;AAKL,IAAA,cAAc,EAAE;AALX,GAAP;AAOD;AAED,OAAM,SAAU,gBAAV,CACJ,UADI,EAEJ,eAFI,EAEqB;AAEzB,MAAI,MAAM,GAAG,EAAb;AAEA,MAAI,aAAa,GAAG,mBAAmB,CAAC,UAAD,CAAvC;AACA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,aAAa,CAAC,MAA5B,CAAT;AAEA,MAAI,aAAa,GAAG,mBAAmB,CAAC,aAAa,CAAC,KAAf,CAAvC;AACA,MAAI,eAAe,GAAG,aAAa,CAAC,KAApC;AACA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,aAAa,CAAC,MAA5B,CAAT;AAEA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,qBAAqB,CAAC,eAAD,CAAnC,CAAT;AAEA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,oBAAoB,CAAC,eAAD,CAAlC,CAAT;AAEA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CACP,uBAAuB,CAAC,eAAD,EAAkB,eAAlB,CADhB,CAAT;AAIA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,uBAAuB,CAAC,eAAD,CAArC,CAAT;AAEA,SAAO,MAAP;AACD;;AAED,SAAS,qBAAT,CACE,UADF,EACyB;AAEvB,MAAI,MAAM,GAAG,EAAb;AACA,MAAI,kBAAkB,GAAG,MAAM,CAAC,UAAD,EAAa,UAAC,WAAD,EAAY;AACtD,WAAA,QAAQ,CAAC,WAAW,CAAC,OAAD,CAAZ,CAAR;AAA8B,GADD,CAA/B;AAIA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,oBAAoB,CAAC,kBAAD,CAAlC,CAAT;AAEA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,sBAAsB,CAAC,kBAAD,CAApC,CAAT;AAEA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,oBAAoB,CAAC,kBAAD,CAAlC,CAAT;AAEA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,qBAAqB,CAAC,kBAAD,CAAnC,CAAT;AAEA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,qBAAqB,CAAC,kBAAD,CAAnC,CAAT;AAEA,SAAO,MAAP;AACD;;AAOD,OAAM,SAAU,mBAAV,CACJ,UADI,EACmB;AAEvB,MAAI,4BAA4B,GAAG,MAAM,CAAC,UAAD,EAAa,UAAC,QAAD,EAAS;AAC7D,WAAO,CAAC,GAAG,CAAC,QAAD,EAAW,OAAX,CAAX;AACD,GAFwC,CAAzC;AAIA,MAAI,MAAM,GAAG,GAAG,CAAC,4BAAD,EAA+B,UAAC,QAAD,EAAS;AACtD,WAAO;AACL,MAAA,OAAO,EACL,mBACA,QAAQ,CAAC,IADT,GAEA,sCAJG;AAKL,MAAA,IAAI,EAAE,wBAAwB,CAAC,eAL1B;AAML,MAAA,UAAU,EAAE,CAAC,QAAD;AANP,KAAP;AAQD,GATe,CAAhB;AAWA,MAAI,KAAK,GAAG,UAAU,CAAC,UAAD,EAAa,4BAAb,CAAtB;AACA,SAAO;AAAE,IAAA,MAAM,EAAA,MAAR;AAAU,IAAA,KAAK,EAAA;AAAf,GAAP;AACD;AAED,OAAM,SAAU,mBAAV,CACJ,UADI,EACmB;AAEvB,MAAI,4BAA4B,GAAG,MAAM,CAAC,UAAD,EAAa,UAAC,QAAD,EAAS;AAC7D,QAAI,OAAO,GAAG,QAAQ,CAAC,OAAD,CAAtB;AACA,WACE,CAAC,QAAQ,CAAC,OAAD,CAAT,IACA,CAAC,UAAU,CAAC,OAAD,CADX,IAEA,CAAC,GAAG,CAAC,OAAD,EAAU,MAAV,CAFJ,IAGA,CAAC,QAAQ,CAAC,OAAD,CAJX;AAMD,GARwC,CAAzC;AAUA,MAAI,MAAM,GAAG,GAAG,CAAC,4BAAD,EAA+B,UAAC,QAAD,EAAS;AACtD,WAAO;AACL,MAAA,OAAO,EACL,mBACA,QAAQ,CAAC,IADT,GAEA,6CAFA,GAGA,8GALG;AAML,MAAA,IAAI,EAAE,wBAAwB,CAAC,eAN1B;AAOL,MAAA,UAAU,EAAE,CAAC,QAAD;AAPP,KAAP;AASD,GAVe,CAAhB;AAYA,MAAI,KAAK,GAAG,UAAU,CAAC,UAAD,EAAa,4BAAb,CAAtB;AACA,SAAO;AAAE,IAAA,MAAM,EAAA,MAAR;AAAU,IAAA,KAAK,EAAA;AAAf,GAAP;AACD;AAED,IAAM,YAAY,GAAG,WAArB;AAEA,OAAM,SAAU,oBAAV,CACJ,UADI,EACmB;AAEvB,MAAA,eAAA;AAAA;AAAA,YAAA,MAAA,EAAA;AAA8B,IAAA,SAAA,CAAA,eAAA,EAAA,MAAA,CAAA;;AAA9B,aAAA,eAAA,GAAA;AAAA,UAAA,KAAA,GAAA,MAAA,KAAA,IAAA,IAAA,MAAA,CAAA,KAAA,CAAA,IAAA,EAAA,SAAA,CAAA,IAAA,IAAA;;AACE,MAAA,KAAA,CAAA,KAAA,GAAQ,KAAR;;AAKD;;AAHC,IAAA,eAAA,CAAA,SAAA,CAAA,cAAA,GAAA,UAAe,IAAf,EAAmB;AACjB,WAAK,KAAL,GAAa,IAAb;AACD,KAFD;;AAGF,WAAA,eAAA;AAAC,GAND,CAA8B,iBAA9B,CAAA;;AAQA,MAAI,YAAY,GAAG,MAAM,CAAC,UAAD,EAAa,UAAC,QAAD,EAAS;AAC7C,QAAM,OAAO,GAAG,QAAQ,CAAC,OAAD,CAAxB;;AAEA,QAAI;AACF,UAAM,SAAS,GAAG,YAAY,CAAC,OAAD,CAA9B;AACA,UAAM,gBAAgB,GAAG,IAAI,eAAJ,EAAzB;AACA,MAAA,gBAAgB,CAAC,KAAjB,CAAuB,SAAvB;AAEA,aAAO,gBAAgB,CAAC,KAAxB;AACD,KAND,CAME,OAAO,CAAP,EAAU;AACV;;AACA;AACA,aAAO,YAAY,CAAC,IAAb,CAAkB,OAAO,CAAC,MAA1B,CAAP;AACD;AACF,GAdwB,CAAzB;AAgBA,MAAI,MAAM,GAAG,GAAG,CAAC,YAAD,EAAe,UAAC,QAAD,EAAS;AACtC,WAAO;AACL,MAAA,OAAO,EACL,sCACA,kBADA,GAEA,QAAQ,CAAC,IAFT,GAGA,8DAHA,GAIA,+EAJA,GAKA,gBAPG;AAQL,MAAA,IAAI,EAAE,wBAAwB,CAAC,gBAR1B;AASL,MAAA,UAAU,EAAE,CAAC,QAAD;AATP,KAAP;AAWD,GAZe,CAAhB;AAcA,SAAO,MAAP;AACD;AAED,OAAM,SAAU,qBAAV,CACJ,UADI,EACmB;AAEvB,MAAI,kBAAkB,GAAG,MAAM,CAAC,UAAD,EAAa,UAAC,QAAD,EAAS;AACnD,QAAI,OAAO,GAAG,QAAQ,CAAC,OAAD,CAAtB;AACA,WAAO,OAAO,CAAC,IAAR,CAAa,EAAb,CAAP;AACD,GAH8B,CAA/B;AAKA,MAAI,MAAM,GAAG,GAAG,CAAC,kBAAD,EAAqB,UAAC,QAAD,EAAS;AAC5C,WAAO;AACL,MAAA,OAAO,EACL,mBACA,QAAQ,CAAC,IADT,GAEA,oDAJG;AAKL,MAAA,IAAI,EAAE,wBAAwB,CAAC,mBAL1B;AAML,MAAA,UAAU,EAAE,CAAC,QAAD;AANP,KAAP;AAQD,GATe,CAAhB;AAWA,SAAO,MAAP;AACD;AAED,IAAM,cAAc,GAAG,gBAAvB;AAEA,OAAM,SAAU,sBAAV,CACJ,UADI,EACmB;AAEvB,MAAA,iBAAA;AAAA;AAAA,YAAA,MAAA,EAAA;AAAgC,IAAA,SAAA,CAAA,iBAAA,EAAA,MAAA,CAAA;;AAAhC,aAAA,iBAAA,GAAA;AAAA,UAAA,KAAA,GAAA,MAAA,KAAA,IAAA,IAAA,MAAA,CAAA,KAAA,CAAA,IAAA,EAAA,SAAA,CAAA,IAAA,IAAA;;AACE,MAAA,KAAA,CAAA,KAAA,GAAQ,KAAR;;AAKD;;AAHC,IAAA,iBAAA,CAAA,SAAA,CAAA,gBAAA,GAAA,UAAiB,IAAjB,EAAqB;AACnB,WAAK,KAAL,GAAa,IAAb;AACD,KAFD;;AAGF,WAAA,iBAAA;AAAC,GAND,CAAgC,iBAAhC,CAAA;;AAQA,MAAI,YAAY,GAAG,MAAM,CAAC,UAAD,EAAa,UAAC,QAAD,EAAS;AAC7C,QAAM,OAAO,GAAG,QAAQ,CAAC,OAAD,CAAxB;;AACA,QAAI;AACF,UAAM,SAAS,GAAG,YAAY,CAAC,OAAD,CAA9B;AACA,UAAM,kBAAkB,GAAG,IAAI,iBAAJ,EAA3B;AACA,MAAA,kBAAkB,CAAC,KAAnB,CAAyB,SAAzB;AAEA,aAAO,kBAAkB,CAAC,KAA1B;AACD,KAND,CAME,OAAO,CAAP,EAAU;AACV;;AACA;AACA,aAAO,cAAc,CAAC,IAAf,CAAoB,OAAO,CAAC,MAA5B,CAAP;AACD;AACF,GAbwB,CAAzB;AAeA,MAAI,MAAM,GAAG,GAAG,CAAC,YAAD,EAAe,UAAC,QAAD,EAAS;AACtC,WAAO;AACL,MAAA,OAAO,EACL,sCACA,kBADA,GAEA,QAAQ,CAAC,IAFT,GAGA,gEAHA,GAIA,uFAJA,GAKA,gBAPG;AAQL,MAAA,IAAI,EAAE,wBAAwB,CAAC,gBAR1B;AASL,MAAA,UAAU,EAAE,CAAC,QAAD;AATP,KAAP;AAWD,GAZe,CAAhB;AAcA,SAAO,MAAP;AACD;AAED,OAAM,SAAU,oBAAV,CACJ,UADI,EACmB;AAEvB,MAAI,YAAY,GAAG,MAAM,CAAC,UAAD,EAAa,UAAC,QAAD,EAAS;AAC7C,QAAI,OAAO,GAAG,QAAQ,CAAC,OAAD,CAAtB;AACA,WAAO,OAAO,YAAY,MAAnB,KAA8B,OAAO,CAAC,SAAR,IAAqB,OAAO,CAAC,MAA3D,CAAP;AACD,GAHwB,CAAzB;AAKA,MAAI,MAAM,GAAG,GAAG,CAAC,YAAD,EAAe,UAAC,QAAD,EAAS;AACtC,WAAO;AACL,MAAA,OAAO,EACL,mBACA,QAAQ,CAAC,IADT,GAEA,mEAJG;AAKL,MAAA,IAAI,EAAE,wBAAwB,CAAC,uBAL1B;AAML,MAAA,UAAU,EAAE,CAAC,QAAD;AANP,KAAP;AAQD,GATe,CAAhB;AAWA,SAAO,MAAP;AACD,C,CAED;;AACA,OAAM,SAAU,qBAAV,CACJ,UADI,EACmB;AAEvB,MAAI,KAAK,GAAG,EAAZ;AACA,MAAI,iBAAiB,GAAG,GAAG,CAAC,UAAD,EAAa,UAAC,SAAD,EAAe;AACrD,WAAO,MAAM,CACX,UADW,EAEX,UAAC,MAAD,EAAS,SAAT,EAAuB;AACrB,UACE,SAAS,CAAC,OAAV,CAAkB,MAAlB,KAA6B,SAAS,CAAC,OAAV,CAAkB,MAA/C,IACA,CAAC,QAAQ,CAAC,KAAD,EAAQ,SAAR,CADT,IAEA,SAAS,CAAC,OAAV,KAAsB,KAAK,CAAC,EAH9B,EAIE;AACA;AACA;AACA,QAAA,KAAK,CAAC,IAAN,CAAW,SAAX;AACA,QAAA,MAAM,CAAC,IAAP,CAAY,SAAZ;AACA,eAAO,MAAP;AACD;;AACD,aAAO,MAAP;AACD,KAfU,EAgBX,EAhBW,CAAb;AAkBD,GAnB0B,CAA3B;AAqBA,EAAA,iBAAiB,GAAG,OAAO,CAAC,iBAAD,CAA3B;AAEA,MAAI,iBAAiB,GAAG,MAAM,CAAC,iBAAD,EAAoB,UAAC,gBAAD,EAAiB;AACjE,WAAO,gBAAgB,CAAC,MAAjB,GAA0B,CAAjC;AACD,GAF6B,CAA9B;AAIA,MAAI,MAAM,GAAG,GAAG,CAAC,iBAAD,EAAoB,UAAC,cAAD,EAAoB;AACtD,QAAI,cAAc,GAAG,GAAG,CAAC,cAAD,EAAiB,UAAC,QAAD,EAAc;AACrD,aAAO,QAAQ,CAAC,IAAhB;AACD,KAFuB,CAAxB;AAIA,QAAI,aAAa,GAAS,KAAK,CAAC,cAAD,CAAL,CAAuB,OAAjD;AACA,WAAO;AACL,MAAA,OAAO,EACL,+BAA6B,aAA7B,GAA0C,IAA1C,IACA,wDAAsD,cAAc,CAAC,IAAf,CACpD,IADoD,CAAtD,GAEC,KAHD,CAFG;AAML,MAAA,IAAI,EAAE,wBAAwB,CAAC,wBAN1B;AAOL,MAAA,UAAU,EAAE;AAPP,KAAP;AASD,GAfe,CAAhB;AAiBA,SAAO,MAAP;AACD;AAED,OAAM,SAAU,oBAAV,CACJ,UADI,EACmB;AAEvB,MAAI,YAAY,GAAG,MAAM,CAAC,UAAD,EAAa,UAAC,KAAD,EAAW;AAC/C,QAAI,CAAC,GAAG,CAAC,KAAD,EAAQ,OAAR,CAAR,EAA0B;AACxB,aAAO,KAAP;AACD;;AACD,QAAI,KAAK,GAAG,KAAK,CAAC,KAAlB;AAEA,WAAO,KAAK,KAAK,KAAK,CAAC,OAAhB,IAA2B,KAAK,KAAK,KAAK,CAAC,EAA3C,IAAiD,CAAC,QAAQ,CAAC,KAAD,CAAjE;AACD,GAPwB,CAAzB;AASA,MAAI,MAAM,GAAG,GAAG,CAAC,YAAD,EAAe,UAAC,QAAD,EAAS;AACtC,WAAO;AACL,MAAA,OAAO,EACL,mBACA,QAAQ,CAAC,IADT,GAEA,+DAJG;AAKL,MAAA,IAAI,EAAE,wBAAwB,CAAC,wBAL1B;AAML,MAAA,UAAU,EAAE,CAAC,QAAD;AANP,KAAP;AAQD,GATe,CAAhB;AAWA,SAAO,MAAP;AACD;AAED,OAAM,SAAU,uBAAV,CACJ,UADI,EAEJ,UAFI,EAEgB;AAEpB,MAAI,YAAY,GAAG,MAAM,CAAC,UAAD,EAAa,UAAC,KAAD,EAAW;AAC/C,WACE,KAAK,CAAC,SAAN,KAAoB,SAApB,IAAiC,CAAC,QAAQ,CAAC,UAAD,EAAa,KAAK,CAAC,SAAnB,CAD5C;AAGD,GAJwB,CAAzB;AAMA,MAAI,MAAM,GAAG,GAAG,CAAC,YAAD,EAAe,UAAC,OAAD,EAAQ;AACrC,QAAI,GAAG,GACL,mBAAiB,OAAO,CAAC,IAAzB,GAA6B,6DAA7B,GAA2F,OAAO,CAAC,SAAnG,GAA4G,IAA5G,GACA,sBAFF;AAGA,WAAO;AACL,MAAA,OAAO,EAAE,GADJ;AAEL,MAAA,IAAI,EAAE,wBAAwB,CAAC,wBAF1B;AAGL,MAAA,UAAU,EAAE,CAAC,OAAD;AAHP,KAAP;AAKD,GATe,CAAhB;AAWA,SAAO,MAAP;AACD;AAED,OAAM,SAAU,uBAAV,CACJ,UADI,EACmB;AAEvB,MAAM,MAAM,GAAG,EAAf;AAEA,MAAM,WAAW,GAAG,MAAM,CACxB,UADwB,EAExB,UAAC,MAAD,EAAS,OAAT,EAAkB,GAAlB,EAAqB;AACnB,QAAM,OAAO,GAAG,OAAO,CAAC,OAAxB;;AAEA,QAAI,OAAO,KAAK,KAAK,CAAC,EAAtB,EAA0B;AACxB,aAAO,MAAP;AACD,KALkB,CAOnB;AACA;;;AACA,QAAI,QAAQ,CAAC,OAAD,CAAZ,EAAuB;AACrB,MAAA,MAAM,CAAC,IAAP,CAAY;AAAE,QAAA,GAAG,EAAE,OAAP;AAAgB,QAAA,GAAG,EAAA,GAAnB;AAAqB,QAAA,SAAS,EAAE;AAAhC,OAAZ;AACD,KAFD,MAEO,IAAI,QAAQ,CAAC,OAAD,CAAR,IAAqB,UAAU,CAAC,OAAD,CAAnC,EAA8C;AACnD,MAAA,MAAM,CAAC,IAAP,CAAY;AAAE,QAAA,GAAG,EAAE,OAAO,CAAC,MAAf;AAAuB,QAAA,GAAG,EAAA,GAA1B;AAA4B,QAAA,SAAS,EAAE;AAAvC,OAAZ;AACD;;AACD,WAAO,MAAP;AACD,GAjBuB,EAkBxB,EAlBwB,CAA1B;AAqBA,EAAA,OAAO,CAAC,UAAD,EAAa,UAAC,OAAD,EAAU,OAAV,EAAiB;AACnC,IAAA,OAAO,CAAC,WAAD,EAAc,UAAC,EAAD,EAAwB;UAArB,GAAA,GAAA,EAAA,CAAA,G;UAAK,GAAA,GAAA,EAAA,CAAA,G;UAAK,SAAA,GAAA,EAAA,CAAA,S;;AAChC,UAAI,OAAO,GAAG,GAAV,IAAiB,aAAa,CAAC,GAAD,EAAM,OAAO,CAAC,OAAd,CAAlC,EAA0D;AACxD,YAAI,GAAG,GACL,cAAY,SAAS,CAAC,IAAtB,GAA0B,4BAA1B,IACA,+CAA6C,OAAO,CAAC,IAArD,GAAyD,IADzD,IAEA,8BAFA,GAGA,yFAJF;AAKA,QAAA,MAAM,CAAC,IAAP,CAAY;AACV,UAAA,OAAO,EAAE,GADC;AAEV,UAAA,IAAI,EAAE,wBAAwB,CAAC,mBAFrB;AAGV,UAAA,UAAU,EAAE,CAAC,OAAD,EAAU,SAAV;AAHF,SAAZ;AAKD;AACF,KAbM,CAAP;AAcD,GAfM,CAAP;AAiBA,SAAO,MAAP;AACD;;AAED,SAAS,aAAT,CAAuB,GAAvB,EAAoC,OAApC,EAAgD;AAC9C;AACA,MAAI,QAAQ,CAAC,OAAD,CAAZ,EAAuB;AACrB,QAAM,WAAW,GAAG,OAAO,CAAC,IAAR,CAAa,GAAb,CAApB;AACA,WAAO,WAAW,KAAK,IAAhB,IAAwB,WAAW,CAAC,KAAZ,KAAsB,CAArD;AACD,GAHD,MAGO,IAAI,UAAU,CAAC,OAAD,CAAd,EAAyB;AAC9B;AACA,WAAO,OAAO,CAAC,GAAD,EAAM,CAAN,EAAS,EAAT,EAAa,EAAb,CAAd;AACD,GAHM,MAGA,IAAI,GAAG,CAAC,OAAD,EAAU,MAAV,CAAP,EAA0B;AAC/B;AACA,WAAO,OAAO,CAAC,IAAR,CAAa,GAAb,EAAkB,CAAlB,EAAqB,EAArB,EAAyB,EAAzB,CAAP;AACD,GAHM,MAGA,IAAI,OAAO,OAAP,KAAmB,QAAvB,EAAiC;AACtC,WAAO,OAAO,KAAK,GAAnB;AACD,GAFM,MAEA;AACL,UAAM,KAAK,CAAC,sBAAD,CAAX;AACD;AACF;;AAED,SAAS,UAAT,CAAoB,MAApB,EAAkC;AAChC;AACA,MAAM,SAAS,GAAG,CAChB,GADgB,EAEhB,IAFgB,EAGhB,GAHgB,EAIhB,GAJgB,EAKhB,GALgB,EAMhB,GANgB,EAOhB,GAPgB,EAQhB,GARgB,EAShB,GATgB,EAUhB,GAVgB,EAWhB,GAXgB,EAYhB,GAZgB,EAahB,GAbgB,CAAlB;AAeA,SACE,IAAI,CAAC,SAAD,EAAY,UAAC,IAAD,EAAK;AAAK,WAAA,MAAM,CAAC,MAAP,CAAc,OAAd,CAAsB,IAAtB,MAAgC,CAAhC,CAAA;AAAkC,GAAxD,CAAJ,KAAkE,SADpE;AAGD;;AAED,OAAM,SAAU,eAAV,CAA0B,OAA1B,EAAyC;AAC7C,MAAI,KAAK,GAAG,OAAO,CAAC,UAAR,GAAqB,GAArB,GAA2B,EAAvC,CAD6C,CAE7C;AACA;;AACA,SAAO,IAAI,MAAJ,CAAW,SAAO,OAAO,CAAC,MAAf,GAAqB,GAAhC,EAAqC,KAArC,CAAP;AACD;AAED,OAAM,SAAU,aAAV,CAAwB,OAAxB,EAAuC;AAC3C,MAAI,KAAK,GAAG,OAAO,CAAC,UAAR,GAAqB,IAArB,GAA4B,GAAxC,CAD2C,CAE3C;AACA;;AACA,SAAO,IAAI,MAAJ,CAAW,KAAG,OAAO,CAAC,MAAtB,EAAgC,KAAhC,CAAP;AACD;AAED,OAAM,SAAU,oBAAV,CACJ,eADI,EAEJ,UAFI,EAGJ,wBAHI,EAGyC;AAE7C,MAAI,MAAM,GAAG,EAAb,CAF6C,CAI7C;;AACA,MAAI,CAAC,GAAG,CAAC,eAAD,EAAkB,YAAlB,CAAR,EAAyC;AACvC,IAAA,MAAM,CAAC,IAAP,CAAY;AACV,MAAA,OAAO,EACL,wDACA,YADA,GAEA,gCAJQ;AAKV,MAAA,IAAI,EAAE,wBAAwB,CAAC;AALrB,KAAZ;AAOD;;AACD,MAAI,CAAC,GAAG,CAAC,eAAD,EAAkB,KAAlB,CAAR,EAAkC;AAChC,IAAA,MAAM,CAAC,IAAP,CAAY;AACV,MAAA,OAAO,EACL,wDACA,KADA,GAEA,gCAJQ;AAKV,MAAA,IAAI,EAAE,wBAAwB,CAAC;AALrB,KAAZ;AAOD;;AAED,MACE,GAAG,CAAC,eAAD,EAAkB,KAAlB,CAAH,IACA,GAAG,CAAC,eAAD,EAAkB,YAAlB,CADH,IAEA,CAAC,GAAG,CAAC,eAAe,CAAC,KAAjB,EAAwB,eAAe,CAAC,WAAxC,CAHN,EAIE;AACA,IAAA,MAAM,CAAC,IAAP,CAAY;AACV,MAAA,OAAO,EACL,oDAAkD,YAAlD,GAA8D,KAA9D,GAAoE,eAAe,CAAC,WAApF,GAA+F,GAA/F,GACA,wBAHQ;AAIV,MAAA,IAAI,EACF,wBAAwB,CAAC;AALjB,KAAZ;AAOD;;AAED,MAAI,GAAG,CAAC,eAAD,EAAkB,KAAlB,CAAP,EAAiC;AAC/B,IAAA,OAAO,CAAC,eAAe,CAAC,KAAjB,EAAwB,UAAC,aAAD,EAAgB,YAAhB,EAA4B;AACzD,MAAA,OAAO,CAAC,aAAD,EAAgB,UAAC,WAAD,EAAc,OAAd,EAAqB;AAC1C,YAAI,WAAW,CAAC,WAAD,CAAf,EAA8B;AAC5B,UAAA,MAAM,CAAC,IAAP,CAAY;AACV,YAAA,OAAO,EACL,wEACA,MAAI,YAAJ,GAAgB,eAAhB,GAAgC,OAAhC,GAAuC,KADvC,CAFQ;AAIV,YAAA,IAAI,EACF,wBAAwB,CAAC;AALjB,WAAZ;AAOD;AACF,OAVM,CAAP;AAWD,KAZM,CAAP;AAaD;;AAED,SAAO,MAAP;AACD;AAED,OAAM,SAAU,2BAAV,CACJ,eADI,EAEJ,UAFI,EAGJ,wBAHI,EAGyC;AAE7C,MAAM,QAAQ,GAAG,EAAjB;AACA,MAAI,eAAe,GAAG,KAAtB;AACA,MAAM,aAAa,GAAG,OAAO,CAC3B,OAAO,CAAC,SAAS,CAAC,eAAe,CAAC,KAAjB,EAAwB,UAAC,QAAD,EAAS;AAAK,WAAA,QAAA;AAAQ,GAA9C,CAAV,CADoB,CAA7B;AAIA,MAAM,kBAAkB,GAAG,MAAM,CAC/B,aAD+B,EAE/B,UAAC,QAAD,EAAS;AAAK,WAAA,QAAQ,CAAC,OAAD,CAAR,KAAsB,KAAK,CAA3B,EAAA;AAA8B,GAFb,CAAjC;AAIA,MAAM,mBAAmB,GAAG,YAAY,CAAC,wBAAD,CAAxC;;AACA,MAAI,UAAJ,EAAgB;AACd,IAAA,OAAO,CAAC,kBAAD,EAAqB,UAAC,OAAD,EAAQ;AAClC,UAAM,SAAS,GAAG,qBAAqB,CAAC,OAAD,EAAU,mBAAV,CAAvC;;AACA,UAAI,SAAS,KAAK,KAAlB,EAAyB;AACvB,YAAM,OAAO,GAAG,0BAA0B,CAAC,OAAD,EAAU,SAAV,CAA1C;AACA,YAAM,iBAAiB,GAAG;AACxB,UAAA,OAAO,EAAA,OADiB;AAExB,UAAA,IAAI,EAAE,SAAS,CAAC,KAFQ;AAGxB,UAAA,SAAS,EAAE;AAHa,SAA1B;AAKA,QAAA,QAAQ,CAAC,IAAT,CAAc,iBAAd;AACD,OARD,MAQO;AACL;AACA,YAAI,GAAG,CAAC,OAAD,EAAU,aAAV,CAAP,EAAiC;AAC/B,cAAI,OAAO,CAAC,WAAR,KAAwB,IAA5B,EAAkC;AAChC,YAAA,eAAe,GAAG,IAAlB;AACD;AACF,SAJD,MAIO;AACL,cAAI,gBAAgB,CAAC,mBAAD,EAAsB,OAAO,CAAC,OAA9B,CAApB,EAA4D;AAC1D,YAAA,eAAe,GAAG,IAAlB;AACD;AACF;AACF;AACF,KAtBM,CAAP;AAuBD;;AAED,MAAI,UAAU,IAAI,CAAC,eAAnB,EAAoC;AAClC,IAAA,QAAQ,CAAC,IAAT,CAAc;AACZ,MAAA,OAAO,EACL,qCACA,uEADA,GAEA,kFAFA,GAGA,8FAHA,GAIA,gBANU;AAOZ,MAAA,IAAI,EAAE,wBAAwB,CAAC;AAPnB,KAAd;AASD;;AACD,SAAO,QAAP;AACD;AAED,OAAM,SAAU,gBAAV,CAA2B,WAA3B,EAEL;AACC,MAAI,YAAY,GAAQ,EAAxB;AACA,MAAI,SAAS,GAAG,IAAI,CAAC,WAAD,CAApB;AAEA,EAAA,OAAO,CAAC,SAAD,EAAY,UAAC,OAAD,EAAQ;AACzB,QAAI,cAAc,GAAG,WAAW,CAAC,OAAD,CAAhC;AAEA;;AACA,QAAI,OAAO,CAAC,cAAD,CAAX,EAA6B;AAC3B,MAAA,YAAY,CAAC,OAAD,CAAZ,GAAwB,EAAxB;AACD,KAFD,MAEO;AACL,YAAM,KAAK,CAAC,sBAAD,CAAX;AACD;AACF,GATM,CAAP;AAWA,SAAO,YAAP;AACD,C,CAED;;AACA,OAAM,SAAU,eAAV,CAA0B,SAA1B,EAAwC;AAC5C,MAAI,OAAO,GAAG,SAAS,CAAC,OAAxB;AACA;;AACA,MAAI,QAAQ,CAAC,OAAD,CAAZ,EAAuB;AACrB,WAAO,KAAP;AACD,GAFD,MAEO,IAAI,UAAU,CAAC,OAAD,CAAd,EAAyB;AAC9B;AACA,WAAO,IAAP;AACD,GAHM,MAGA,IAAI,GAAG,CAAC,OAAD,EAAU,MAAV,CAAP,EAA0B;AAC/B;AACA,WAAO,IAAP;AACD,GAHM,MAGA,IAAI,QAAQ,CAAC,OAAD,CAAZ,EAAuB;AAC5B,WAAO,KAAP;AACD,GAFM,MAEA;AACL,UAAM,KAAK,CAAC,sBAAD,CAAX;AACD;AACF;AAED,OAAM,SAAU,cAAV,CAAyB,OAAzB,EAAqC;AACzC,MAAI,QAAQ,CAAC,OAAD,CAAR,IAAqB,OAAO,CAAC,MAAR,KAAmB,CAA5C,EAA+C;AAC7C,WAAO,OAAO,CAAC,UAAR,CAAmB,CAAnB,CAAP;AACD,GAFD,MAEO;AACL,WAAO,KAAP;AACD;AACF;AAED;;;;AAGA,OAAO,IAAM,6BAA6B,GAA2B;AACnE;AACA,EAAA,IAAI,EAAE,UAAU,IAAV,EAAc;AAClB,QAAI,GAAG,GAAG,IAAI,CAAC,MAAf;;AACA,SAAK,IAAI,CAAC,GAAG,KAAK,SAAlB,EAA6B,CAAC,GAAG,GAAjC,EAAsC,CAAC,EAAvC,EAA2C;AACzC,UAAI,CAAC,GAAG,IAAI,CAAC,UAAL,CAAgB,CAAhB,CAAR;;AACA,UAAI,CAAC,KAAK,EAAV,EAAc;AACZ,aAAK,SAAL,GAAiB,CAAC,GAAG,CAArB;AACA,eAAO,IAAP;AACD,OAHD,MAGO,IAAI,CAAC,KAAK,EAAV,EAAc;AACnB,YAAI,IAAI,CAAC,UAAL,CAAgB,CAAC,GAAG,CAApB,MAA2B,EAA/B,EAAmC;AACjC,eAAK,SAAL,GAAiB,CAAC,GAAG,CAArB;AACD,SAFD,MAEO;AACL,eAAK,SAAL,GAAiB,CAAC,GAAG,CAArB;AACD;;AACD,eAAO,IAAP;AACD;AACF;;AACD,WAAO,KAAP;AACD,GAnBkE;AAqBnE,EAAA,SAAS,EAAE;AArBwD,CAA9D;;AAwBP,SAAS,qBAAT,CACE,OADF,EAEE,uBAFF,EAEmC;AASjC,MAAI,GAAG,CAAC,OAAD,EAAU,aAAV,CAAP,EAAiC;AAC/B;AACA;AACA,WAAO,KAAP;AACD,GAJD,MAIO;AACL;AACA,QAAI,QAAQ,CAAC,OAAO,CAAC,OAAT,CAAZ,EAA+B;AAC7B,UAAI;AACF,QAAA,gBAAgB,CAAC,uBAAD,EAA0B,OAAO,CAAC,OAAlC,CAAhB;AACD,OAFD,CAEE,OAAO,CAAP,EAAU;AACV;AACA,eAAO;AACL,UAAA,KAAK,EAAE,wBAAwB,CAAC,mBAD3B;AAEL,UAAA,MAAM,EAAE,CAAC,CAAC;AAFL,SAAP;AAID;;AACD,aAAO,KAAP;AACD,KAXD,MAWO,IAAI,QAAQ,CAAC,OAAO,CAAC,OAAT,CAAZ,EAA+B;AACpC;AACA,aAAO,KAAP;AACD,KAHM,MAGA,IAAI,eAAe,CAAC,OAAD,CAAnB,EAA8B;AACnC;AACA,aAAO;AAAE,QAAA,KAAK,EAAE,wBAAwB,CAAC;AAAlC,OAAP;AACD,KAHM,MAGA;AACL,YAAM,KAAK,CAAC,sBAAD,CAAX;AACD;AACF;AACF;;AAED,OAAM,SAAU,0BAAV,CACJ,OADI,EAEJ,OAFI,EAOH;AAED;AACA,MAAI,OAAO,CAAC,KAAR,KAAkB,wBAAwB,CAAC,mBAA/C,EAAoE;AAClE,WACE,qEACA,8BAA4B,OAAO,CAAC,IAApC,GAAwC,gBADxC,KAEA,oBAAkB,OAAO,CAAC,MAA1B,GAAgC,KAFhC,IAGA,gHAJF;AAMD,GAPD,MAOO,IAAI,OAAO,CAAC,KAAR,KAAkB,wBAAwB,CAAC,iBAA/C,EAAkE;AACvE,WACE,gFACA,8BAA4B,OAAO,CAAC,IAApC,GAAwC,gBADxC,IAEA,8GAHF;AAKD,GANM,MAMA;AACL,UAAM,KAAK,CAAC,sBAAD,CAAX;AACD;AACF;;AAED,SAAS,YAAT,CAAsB,YAAtB,EAAuD;AACrD,MAAM,SAAS,GAAG,GAAG,CAAC,YAAD,EAAe,UAAC,WAAD,EAAY;AAC9C,QAAI,QAAQ,CAAC,WAAD,CAAR,IAAyB,WAAW,CAAC,MAAZ,GAAqB,CAAlD,EAAqD;AACnD,aAAO,WAAW,CAAC,UAAZ,CAAuB,CAAvB,CAAP;AACD,KAFD,MAEO;AACL,aAAO,WAAP;AACD;AACF,GANoB,CAArB;AAQA,SAAO,SAAP;AACD;;AAED,SAAS,gBAAT,CAA0B,GAA1B,EAA+B,GAA/B,EAAoC,KAApC,EAAyC;AACvC,MAAI,GAAG,CAAC,GAAD,CAAH,KAAa,SAAjB,EAA4B;AAC1B,IAAA,GAAG,CAAC,GAAD,CAAH,GAAW,CAAC,KAAD,CAAX;AACD,GAFD,MAEO;AACL,IAAA,GAAG,CAAC,GAAD,CAAH,CAAS,IAAT,CAAc,KAAd;AACD;AACF;;AAED,OAAO,IAAM,kBAAkB,GAAG,GAA3B;AAEP;;;;;;;;;;;;;;;;AAeA,OAAM,SAAU,wBAAV,CAAmC,QAAnC,EAA2C;AAC/C,SAAO,QAAQ,GAAG,kBAAX,GACH,QADG,GAEH,yBAAyB,CAAC,QAAD,CAF7B;AAGD;AAED;;;;;;;;;AAQA,IAAI,yBAAyB,GAAG,EAAhC;;AACA,SAAS,+BAAT,GAAwC;AACtC,MAAI,OAAO,CAAC,yBAAD,CAAX,EAAwC;AACtC,IAAA,yBAAyB,GAAG,IAAI,KAAJ,CAAU,KAAV,CAA5B;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAApB,EAA2B,CAAC,EAA5B,EAAgC;AAC9B;AACA,MAAA,yBAAyB,CAAC,CAAD,CAAzB,GAA+B,CAAC,GAAG,GAAJ,GAAU,MAAM,CAAC,EAAE,CAAC,GAAG,GAAN,CAAjB,GAA8B,CAA7D;AACA;AACD;AACF;AACF","sourceRoot":"","sourcesContent":["var __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nimport { BaseRegExpVisitor } from \"regexp-to-ast\";\nimport { Lexer, LexerDefinitionErrorType } from \"./lexer_public\";\nimport { compact, contains, defaults, difference, filter, find, first, flatten, forEach, has, indexOf, isArray, isEmpty, isFunction, isRegExp, isString, isUndefined, keys, map, mapValues, packArray, PRINT_ERROR, reduce, reject } from \"../utils/utils\";\nimport { canMatchCharCode, failedOptimizationPrefixMsg, getOptimizedStartCodesIndices } from \"./reg_exp\";\nimport { getRegExpAst } from \"./reg_exp_parser\";\nvar PATTERN = \"PATTERN\";\nexport var DEFAULT_MODE = \"defaultMode\";\nexport var MODES = \"modes\";\nexport var SUPPORT_STICKY = typeof new RegExp(\"(?:)\").sticky === \"boolean\";\nexport function disableSticky() {\n    SUPPORT_STICKY = false;\n}\nexport function enableSticky() {\n    SUPPORT_STICKY = true;\n}\nexport function analyzeTokenTypes(tokenTypes, options) {\n    options = defaults(options, {\n        useSticky: SUPPORT_STICKY,\n        debug: false,\n        safeMode: false,\n        positionTracking: \"full\",\n        lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n        tracer: function (msg, action) { return action(); }\n    });\n    var tracer = options.tracer;\n    tracer(\"initCharCodeToOptimizedIndexMap\", function () {\n        initCharCodeToOptimizedIndexMap();\n    });\n    var onlyRelevantTypes;\n    tracer(\"Reject Lexer.NA\", function () {\n        onlyRelevantTypes = reject(tokenTypes, function (currType) {\n            return currType[PATTERN] === Lexer.NA;\n        });\n    });\n    var hasCustom = false;\n    var allTransformedPatterns;\n    tracer(\"Transform Patterns\", function () {\n        hasCustom = false;\n        allTransformedPatterns = map(onlyRelevantTypes, function (currType) {\n            var currPattern = currType[PATTERN];\n            /* istanbul ignore else */\n            if (isRegExp(currPattern)) {\n                var regExpSource = currPattern.source;\n                if (regExpSource.length === 1 &&\n                    // only these regExp meta characters which can appear in a length one regExp\n                    regExpSource !== \"^\" &&\n                    regExpSource !== \"$\" &&\n                    regExpSource !== \".\" &&\n                    !currPattern.ignoreCase) {\n                    return regExpSource;\n                }\n                else if (regExpSource.length === 2 &&\n                    regExpSource[0] === \"\\\\\" &&\n                    // not a meta character\n                    !contains([\n                        \"d\",\n                        \"D\",\n                        \"s\",\n                        \"S\",\n                        \"t\",\n                        \"r\",\n                        \"n\",\n                        \"t\",\n                        \"0\",\n                        \"c\",\n                        \"b\",\n                        \"B\",\n                        \"f\",\n                        \"v\",\n                        \"w\",\n                        \"W\"\n                    ], regExpSource[1])) {\n                    // escaped meta Characters: /\\+/ /\\[/\n                    // or redundant escaping: /\\a/\n                    // without the escaping \"\\\"\n                    return regExpSource[1];\n                }\n                else {\n                    return options.useSticky\n                        ? addStickyFlag(currPattern)\n                        : addStartOfInput(currPattern);\n                }\n            }\n            else if (isFunction(currPattern)) {\n                hasCustom = true;\n                // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n                return { exec: currPattern };\n            }\n            else if (has(currPattern, \"exec\")) {\n                hasCustom = true;\n                // ICustomPattern\n                return currPattern;\n            }\n            else if (typeof currPattern === \"string\") {\n                if (currPattern.length === 1) {\n                    return currPattern;\n                }\n                else {\n                    var escapedRegExpString = currPattern.replace(/[\\\\^$.*+?()[\\]{}|]/g, \"\\\\$&\");\n                    var wrappedRegExp = new RegExp(escapedRegExpString);\n                    return options.useSticky\n                        ? addStickyFlag(wrappedRegExp)\n                        : addStartOfInput(wrappedRegExp);\n                }\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        });\n    });\n    var patternIdxToType;\n    var patternIdxToGroup;\n    var patternIdxToLongerAltIdx;\n    var patternIdxToPushMode;\n    var patternIdxToPopMode;\n    tracer(\"misc mapping\", function () {\n        patternIdxToType = map(onlyRelevantTypes, function (currType) { return currType.tokenTypeIdx; });\n        patternIdxToGroup = map(onlyRelevantTypes, function (clazz) {\n            var groupName = clazz.GROUP;\n            /* istanbul ignore next */\n            if (groupName === Lexer.SKIPPED) {\n                return undefined;\n            }\n            else if (isString(groupName)) {\n                return groupName;\n            }\n            else if (isUndefined(groupName)) {\n                return false;\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        });\n        patternIdxToLongerAltIdx = map(onlyRelevantTypes, function (clazz) {\n            var longerAltType = clazz.LONGER_ALT;\n            if (longerAltType) {\n                var longerAltIdx = indexOf(onlyRelevantTypes, longerAltType);\n                return longerAltIdx;\n            }\n        });\n        patternIdxToPushMode = map(onlyRelevantTypes, function (clazz) { return clazz.PUSH_MODE; });\n        patternIdxToPopMode = map(onlyRelevantTypes, function (clazz) {\n            return has(clazz, \"POP_MODE\");\n        });\n    });\n    var patternIdxToCanLineTerminator;\n    tracer(\"Line Terminator Handling\", function () {\n        var lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\n        patternIdxToCanLineTerminator = map(onlyRelevantTypes, function (tokType) { return false; });\n        if (options.positionTracking !== \"onlyOffset\") {\n            patternIdxToCanLineTerminator = map(onlyRelevantTypes, function (tokType) {\n                if (has(tokType, \"LINE_BREAKS\")) {\n                    return tokType.LINE_BREAKS;\n                }\n                else {\n                    if (checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false) {\n                        return canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n                    }\n                }\n            });\n        }\n    });\n    var patternIdxToIsCustom;\n    var patternIdxToShort;\n    var emptyGroups;\n    var patternIdxToConfig;\n    tracer(\"Misc Mapping #2\", function () {\n        patternIdxToIsCustom = map(onlyRelevantTypes, isCustomPattern);\n        patternIdxToShort = map(allTransformedPatterns, isShortPattern);\n        emptyGroups = reduce(onlyRelevantTypes, function (acc, clazz) {\n            var groupName = clazz.GROUP;\n            if (isString(groupName) && !(groupName === Lexer.SKIPPED)) {\n                acc[groupName] = [];\n            }\n            return acc;\n        }, {});\n        patternIdxToConfig = map(allTransformedPatterns, function (x, idx) {\n            return {\n                pattern: allTransformedPatterns[idx],\n                longerAlt: patternIdxToLongerAltIdx[idx],\n                canLineTerminator: patternIdxToCanLineTerminator[idx],\n                isCustom: patternIdxToIsCustom[idx],\n                short: patternIdxToShort[idx],\n                group: patternIdxToGroup[idx],\n                push: patternIdxToPushMode[idx],\n                pop: patternIdxToPopMode[idx],\n                tokenTypeIdx: patternIdxToType[idx],\n                tokenType: onlyRelevantTypes[idx]\n            };\n        });\n    });\n    var canBeOptimized = true;\n    var charCodeToPatternIdxToConfig = [];\n    if (!options.safeMode) {\n        tracer(\"First Char Optimization\", function () {\n            charCodeToPatternIdxToConfig = reduce(onlyRelevantTypes, function (result, currTokType, idx) {\n                if (typeof currTokType.PATTERN === \"string\") {\n                    var charCode = currTokType.PATTERN.charCodeAt(0);\n                    var optimizedIdx = charCodeToOptimizedIndex(charCode);\n                    addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n                }\n                else if (isArray(currTokType.START_CHARS_HINT)) {\n                    var lastOptimizedIdx_1;\n                    forEach(currTokType.START_CHARS_HINT, function (charOrInt) {\n                        var charCode = typeof charOrInt === \"string\"\n                            ? charOrInt.charCodeAt(0)\n                            : charOrInt;\n                        var currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n                        // Avoid adding the config multiple times\n                        /* istanbul ignore else */\n                        // - Difficult to check this scenario effects as it is only a performance\n                        //   optimization that does not change correctness\n                        if (lastOptimizedIdx_1 !== currOptimizedIdx) {\n                            lastOptimizedIdx_1 = currOptimizedIdx;\n                            addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\n                        }\n                    });\n                }\n                else if (isRegExp(currTokType.PATTERN)) {\n                    if (currTokType.PATTERN.unicode) {\n                        canBeOptimized = false;\n                        if (options.ensureOptimizations) {\n                            PRINT_ERROR(\"\" + failedOptimizationPrefixMsg +\n                                (\"\\tUnable to analyze < \" + currTokType.PATTERN.toString() + \" > pattern.\\n\") +\n                                \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" +\n                                \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                                \"\\tFor details See: https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\");\n                        }\n                    }\n                    else {\n                        var optimizedCodes = getOptimizedStartCodesIndices(currTokType.PATTERN, options.ensureOptimizations);\n                        /* istanbul ignore if */\n                        // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n                        // the first should be a different validation and the second cannot be tested.\n                        if (isEmpty(optimizedCodes)) {\n                            // we cannot understand what codes may start possible matches\n                            // The optimization correctness requires knowing start codes for ALL patterns.\n                            // Not actually sure this is an error, no debug message\n                            canBeOptimized = false;\n                        }\n                        forEach(optimizedCodes, function (code) {\n                            addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n                        });\n                    }\n                }\n                else {\n                    if (options.ensureOptimizations) {\n                        PRINT_ERROR(\"\" + failedOptimizationPrefixMsg +\n                            (\"\\tTokenType: <\" + currTokType.name + \"> is using a custom token pattern without providing <start_chars_hint> parameter.\\n\") +\n                            \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                            \"\\tFor details See: https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\");\n                    }\n                    canBeOptimized = false;\n                }\n                return result;\n            }, []);\n        });\n    }\n    tracer(\"ArrayPacking\", function () {\n        charCodeToPatternIdxToConfig = packArray(charCodeToPatternIdxToConfig);\n    });\n    return {\n        emptyGroups: emptyGroups,\n        patternIdxToConfig: patternIdxToConfig,\n        charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n        hasCustom: hasCustom,\n        canBeOptimized: canBeOptimized\n    };\n}\nexport function validatePatterns(tokenTypes, validModesNames) {\n    var errors = [];\n    var missingResult = findMissingPatterns(tokenTypes);\n    errors = errors.concat(missingResult.errors);\n    var invalidResult = findInvalidPatterns(missingResult.valid);\n    var validTokenTypes = invalidResult.valid;\n    errors = errors.concat(invalidResult.errors);\n    errors = errors.concat(validateRegExpPattern(validTokenTypes));\n    errors = errors.concat(findInvalidGroupType(validTokenTypes));\n    errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\n    errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n    return errors;\n}\nfunction validateRegExpPattern(tokenTypes) {\n    var errors = [];\n    var withRegExpPatterns = filter(tokenTypes, function (currTokType) {\n        return isRegExp(currTokType[PATTERN]);\n    });\n    errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n    errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n    errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n    return errors;\n}\nexport function findMissingPatterns(tokenTypes) {\n    var tokenTypesWithMissingPattern = filter(tokenTypes, function (currType) {\n        return !has(currType, PATTERN);\n    });\n    var errors = map(tokenTypesWithMissingPattern, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- missing static 'PATTERN' property\",\n            type: LexerDefinitionErrorType.MISSING_PATTERN,\n            tokenTypes: [currType]\n        };\n    });\n    var valid = difference(tokenTypes, tokenTypesWithMissingPattern);\n    return { errors: errors, valid: valid };\n}\nexport function findInvalidPatterns(tokenTypes) {\n    var tokenTypesWithInvalidPattern = filter(tokenTypes, function (currType) {\n        var pattern = currType[PATTERN];\n        return (!isRegExp(pattern) &&\n            !isFunction(pattern) &&\n            !has(pattern, \"exec\") &&\n            !isString(pattern));\n    });\n    var errors = map(tokenTypesWithInvalidPattern, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' can only be a RegExp, a\" +\n                \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n            type: LexerDefinitionErrorType.INVALID_PATTERN,\n            tokenTypes: [currType]\n        };\n    });\n    var valid = difference(tokenTypes, tokenTypesWithInvalidPattern);\n    return { errors: errors, valid: valid };\n}\nvar end_of_input = /[^\\\\][\\$]/;\nexport function findEndOfInputAnchor(tokenTypes) {\n    var EndAnchorFinder = /** @class */ (function (_super) {\n        __extends(EndAnchorFinder, _super);\n        function EndAnchorFinder() {\n            var _this = _super !== null && _super.apply(this, arguments) || this;\n            _this.found = false;\n            return _this;\n        }\n        EndAnchorFinder.prototype.visitEndAnchor = function (node) {\n            this.found = true;\n        };\n        return EndAnchorFinder;\n    }(BaseRegExpVisitor));\n    var invalidRegex = filter(tokenTypes, function (currType) {\n        var pattern = currType[PATTERN];\n        try {\n            var regexpAst = getRegExpAst(pattern);\n            var endAnchorVisitor = new EndAnchorFinder();\n            endAnchorVisitor.visit(regexpAst);\n            return endAnchorVisitor.found;\n        }\n        catch (e) {\n            // old behavior in case of runtime exceptions with regexp-to-ast.\n            /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n            return end_of_input.test(pattern.source);\n        }\n    });\n    var errors = map(invalidRegex, function (currType) {\n        return {\n            message: \"Unexpected RegExp Anchor Error:\\n\" +\n                \"\\tToken Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" +\n                \"\\tSee sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n                \"\\tfor details.\",\n            type: LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexport function findEmptyMatchRegExps(tokenTypes) {\n    var matchesEmptyString = filter(tokenTypes, function (currType) {\n        var pattern = currType[PATTERN];\n        return pattern.test(\"\");\n    });\n    var errors = map(matchesEmptyString, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' must not match an empty string\",\n            type: LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nvar start_of_input = /[^\\\\[][\\^]|^\\^/;\nexport function findStartOfInputAnchor(tokenTypes) {\n    var StartAnchorFinder = /** @class */ (function (_super) {\n        __extends(StartAnchorFinder, _super);\n        function StartAnchorFinder() {\n            var _this = _super !== null && _super.apply(this, arguments) || this;\n            _this.found = false;\n            return _this;\n        }\n        StartAnchorFinder.prototype.visitStartAnchor = function (node) {\n            this.found = true;\n        };\n        return StartAnchorFinder;\n    }(BaseRegExpVisitor));\n    var invalidRegex = filter(tokenTypes, function (currType) {\n        var pattern = currType[PATTERN];\n        try {\n            var regexpAst = getRegExpAst(pattern);\n            var startAnchorVisitor = new StartAnchorFinder();\n            startAnchorVisitor.visit(regexpAst);\n            return startAnchorVisitor.found;\n        }\n        catch (e) {\n            // old behavior in case of runtime exceptions with regexp-to-ast.\n            /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n            return start_of_input.test(pattern.source);\n        }\n    });\n    var errors = map(invalidRegex, function (currType) {\n        return {\n            message: \"Unexpected RegExp Anchor Error:\\n\" +\n                \"\\tToken Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" +\n                \"\\tSee https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n                \"\\tfor details.\",\n            type: LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexport function findUnsupportedFlags(tokenTypes) {\n    var invalidFlags = filter(tokenTypes, function (currType) {\n        var pattern = currType[PATTERN];\n        return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n    });\n    var errors = map(invalidFlags, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n            type: LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nexport function findDuplicatePatterns(tokenTypes) {\n    var found = [];\n    var identicalPatterns = map(tokenTypes, function (outerType) {\n        return reduce(tokenTypes, function (result, innerType) {\n            if (outerType.PATTERN.source === innerType.PATTERN.source &&\n                !contains(found, innerType) &&\n                innerType.PATTERN !== Lexer.NA) {\n                // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n                // in essence we are creating Equivalence classes on equality relation.\n                found.push(innerType);\n                result.push(innerType);\n                return result;\n            }\n            return result;\n        }, []);\n    });\n    identicalPatterns = compact(identicalPatterns);\n    var duplicatePatterns = filter(identicalPatterns, function (currIdenticalSet) {\n        return currIdenticalSet.length > 1;\n    });\n    var errors = map(duplicatePatterns, function (setOfIdentical) {\n        var tokenTypeNames = map(setOfIdentical, function (currType) {\n            return currType.name;\n        });\n        var dupPatternSrc = first(setOfIdentical).PATTERN;\n        return {\n            message: \"The same RegExp pattern ->\" + dupPatternSrc + \"<-\" +\n                (\"has been used in all of the following Token Types: \" + tokenTypeNames.join(\", \") + \" <-\"),\n            type: LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n            tokenTypes: setOfIdentical\n        };\n    });\n    return errors;\n}\nexport function findInvalidGroupType(tokenTypes) {\n    var invalidTypes = filter(tokenTypes, function (clazz) {\n        if (!has(clazz, \"GROUP\")) {\n            return false;\n        }\n        var group = clazz.GROUP;\n        return group !== Lexer.SKIPPED && group !== Lexer.NA && !isString(group);\n    });\n    var errors = map(invalidTypes, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n            type: LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexport function findModesThatDoNotExist(tokenTypes, validModes) {\n    var invalidModes = filter(tokenTypes, function (clazz) {\n        return (clazz.PUSH_MODE !== undefined && !contains(validModes, clazz.PUSH_MODE));\n    });\n    var errors = map(invalidModes, function (tokType) {\n        var msg = \"Token Type: ->\" + tokType.name + \"<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->\" + tokType.PUSH_MODE + \"<-\" +\n            \"which does not exist\";\n        return {\n            message: msg,\n            type: LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n            tokenTypes: [tokType]\n        };\n    });\n    return errors;\n}\nexport function findUnreachablePatterns(tokenTypes) {\n    var errors = [];\n    var canBeTested = reduce(tokenTypes, function (result, tokType, idx) {\n        var pattern = tokType.PATTERN;\n        if (pattern === Lexer.NA) {\n            return result;\n        }\n        // a more comprehensive validation for all forms of regExps would require\n        // deeper regExp analysis capabilities\n        if (isString(pattern)) {\n            result.push({ str: pattern, idx: idx, tokenType: tokType });\n        }\n        else if (isRegExp(pattern) && noMetaChar(pattern)) {\n            result.push({ str: pattern.source, idx: idx, tokenType: tokType });\n        }\n        return result;\n    }, []);\n    forEach(tokenTypes, function (tokType, testIdx) {\n        forEach(canBeTested, function (_a) {\n            var str = _a.str, idx = _a.idx, tokenType = _a.tokenType;\n            if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n                var msg = \"Token: ->\" + tokenType.name + \"<- can never be matched.\\n\" +\n                    (\"Because it appears AFTER the Token Type ->\" + tokType.name + \"<-\") +\n                    \"in the lexer's definition.\\n\" +\n                    \"See https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#UNREACHABLE\";\n                errors.push({\n                    message: msg,\n                    type: LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n                    tokenTypes: [tokType, tokenType]\n                });\n            }\n        });\n    });\n    return errors;\n}\nfunction testTokenType(str, pattern) {\n    /* istanbul ignore else */\n    if (isRegExp(pattern)) {\n        var regExpArray = pattern.exec(str);\n        return regExpArray !== null && regExpArray.index === 0;\n    }\n    else if (isFunction(pattern)) {\n        // maintain the API of custom patterns\n        return pattern(str, 0, [], {});\n    }\n    else if (has(pattern, \"exec\")) {\n        // maintain the API of custom patterns\n        return pattern.exec(str, 0, [], {});\n    }\n    else if (typeof pattern === \"string\") {\n        return pattern === str;\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nfunction noMetaChar(regExp) {\n    //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n    var metaChars = [\n        \".\",\n        \"\\\\\",\n        \"[\",\n        \"]\",\n        \"|\",\n        \"^\",\n        \"$\",\n        \"(\",\n        \")\",\n        \"?\",\n        \"*\",\n        \"+\",\n        \"{\"\n    ];\n    return (find(metaChars, function (char) { return regExp.source.indexOf(char) !== -1; }) === undefined);\n}\nexport function addStartOfInput(pattern) {\n    var flags = pattern.ignoreCase ? \"i\" : \"\";\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n    return new RegExp(\"^(?:\" + pattern.source + \")\", flags);\n}\nexport function addStickyFlag(pattern) {\n    var flags = pattern.ignoreCase ? \"iy\" : \"y\";\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n    return new RegExp(\"\" + pattern.source, flags);\n}\nexport function performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n    var errors = [];\n    // some run time checks to help the end users.\n    if (!has(lexerDefinition, DEFAULT_MODE)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized without a <\" +\n                DEFAULT_MODE +\n                \"> property in its definition\\n\",\n            type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n        });\n    }\n    if (!has(lexerDefinition, MODES)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized without a <\" +\n                MODES +\n                \"> property in its definition\\n\",\n            type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n        });\n    }\n    if (has(lexerDefinition, MODES) &&\n        has(lexerDefinition, DEFAULT_MODE) &&\n        !has(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized with a \" + DEFAULT_MODE + \": <\" + lexerDefinition.defaultMode + \">\" +\n                \"which does not exist\\n\",\n            type: LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n        });\n    }\n    if (has(lexerDefinition, MODES)) {\n        forEach(lexerDefinition.modes, function (currModeValue, currModeName) {\n            forEach(currModeValue, function (currTokType, currIdx) {\n                if (isUndefined(currTokType)) {\n                    errors.push({\n                        message: \"A Lexer cannot be initialized using an undefined Token Type. Mode:\" +\n                            (\"<\" + currModeName + \"> at index: <\" + currIdx + \">\\n\"),\n                        type: LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n                    });\n                }\n            });\n        });\n    }\n    return errors;\n}\nexport function performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n    var warnings = [];\n    var hasAnyLineBreak = false;\n    var allTokenTypes = compact(flatten(mapValues(lexerDefinition.modes, function (tokTypes) { return tokTypes; })));\n    var concreteTokenTypes = reject(allTokenTypes, function (currType) { return currType[PATTERN] === Lexer.NA; });\n    var terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n    if (trackLines) {\n        forEach(concreteTokenTypes, function (tokType) {\n            var currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n            if (currIssue !== false) {\n                var message = buildLineBreakIssueMessage(tokType, currIssue);\n                var warningDescriptor = {\n                    message: message,\n                    type: currIssue.issue,\n                    tokenType: tokType\n                };\n                warnings.push(warningDescriptor);\n            }\n            else {\n                // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n                if (has(tokType, \"LINE_BREAKS\")) {\n                    if (tokType.LINE_BREAKS === true) {\n                        hasAnyLineBreak = true;\n                    }\n                }\n                else {\n                    if (canMatchCharCode(terminatorCharCodes, tokType.PATTERN)) {\n                        hasAnyLineBreak = true;\n                    }\n                }\n            }\n        });\n    }\n    if (trackLines && !hasAnyLineBreak) {\n        warnings.push({\n            message: \"Warning: No LINE_BREAKS Found.\\n\" +\n                \"\\tThis Lexer has been defined to track line and column information,\\n\" +\n                \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" +\n                \"\\tSee https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" +\n                \"\\tfor details.\",\n            type: LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\n        });\n    }\n    return warnings;\n}\nexport function cloneEmptyGroups(emptyGroups) {\n    var clonedResult = {};\n    var groupKeys = keys(emptyGroups);\n    forEach(groupKeys, function (currKey) {\n        var currGroupValue = emptyGroups[currKey];\n        /* istanbul ignore else */\n        if (isArray(currGroupValue)) {\n            clonedResult[currKey] = [];\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n    });\n    return clonedResult;\n}\n// TODO: refactor to avoid duplication\nexport function isCustomPattern(tokenType) {\n    var pattern = tokenType.PATTERN;\n    /* istanbul ignore else */\n    if (isRegExp(pattern)) {\n        return false;\n    }\n    else if (isFunction(pattern)) {\n        // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n        return true;\n    }\n    else if (has(pattern, \"exec\")) {\n        // ICustomPattern\n        return true;\n    }\n    else if (isString(pattern)) {\n        return false;\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nexport function isShortPattern(pattern) {\n    if (isString(pattern) && pattern.length === 1) {\n        return pattern.charCodeAt(0);\n    }\n    else {\n        return false;\n    }\n}\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexport var LineTerminatorOptimizedTester = {\n    // implements /\\n|\\r\\n?/g.test\n    test: function (text) {\n        var len = text.length;\n        for (var i = this.lastIndex; i < len; i++) {\n            var c = text.charCodeAt(i);\n            if (c === 10) {\n                this.lastIndex = i + 1;\n                return true;\n            }\n            else if (c === 13) {\n                if (text.charCodeAt(i + 1) === 10) {\n                    this.lastIndex = i + 2;\n                }\n                else {\n                    this.lastIndex = i + 1;\n                }\n                return true;\n            }\n        }\n        return false;\n    },\n    lastIndex: 0\n};\nfunction checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\n    if (has(tokType, \"LINE_BREAKS\")) {\n        // if the user explicitly declared the line_breaks option we will respect their choice\n        // and assume it is correct.\n        return false;\n    }\n    else {\n        /* istanbul ignore else */\n        if (isRegExp(tokType.PATTERN)) {\n            try {\n                canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n            }\n            catch (e) {\n                /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n                return {\n                    issue: LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n                    errMsg: e.message\n                };\n            }\n            return false;\n        }\n        else if (isString(tokType.PATTERN)) {\n            // string literal patterns can always be analyzed to detect line terminator usage\n            return false;\n        }\n        else if (isCustomPattern(tokType)) {\n            // custom token types\n            return { issue: LexerDefinitionErrorType.CUSTOM_LINE_BREAK };\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n    }\n}\nexport function buildLineBreakIssueMessage(tokType, details) {\n    /* istanbul ignore else */\n    if (details.issue === LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n        return (\"Warning: unable to identify line terminator usage in pattern.\\n\" +\n            (\"\\tThe problem is in the <\" + tokType.name + \"> Token Type\\n\") +\n            (\"\\t Root cause: \" + details.errMsg + \".\\n\") +\n            \"\\tFor details See: https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\");\n    }\n    else if (details.issue === LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n        return (\"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" +\n            (\"\\tThe problem is in the <\" + tokType.name + \"> Token Type\\n\") +\n            \"\\tFor details See: https://sap.github.io/chevrotain/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\");\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nfunction getCharCodes(charsOrCodes) {\n    var charCodes = map(charsOrCodes, function (numOrString) {\n        if (isString(numOrString) && numOrString.length > 0) {\n            return numOrString.charCodeAt(0);\n        }\n        else {\n            return numOrString;\n        }\n    });\n    return charCodes;\n}\nfunction addToMapOfArrays(map, key, value) {\n    if (map[key] === undefined) {\n        map[key] = [value];\n    }\n    else {\n        map[key].push(value);\n    }\n}\nexport var minOptimizationVal = 256;\n/**\n * We ae mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nexport function charCodeToOptimizedIndex(charCode) {\n    return charCode < minOptimizationVal\n        ? charCode\n        : charCodeToOptimizedIdxMap[charCode];\n}\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nvar charCodeToOptimizedIdxMap = [];\nfunction initCharCodeToOptimizedIndexMap() {\n    if (isEmpty(charCodeToOptimizedIdxMap)) {\n        charCodeToOptimizedIdxMap = new Array(65536);\n        for (var i = 0; i < 65536; i++) {\n            /* tslint:disable */\n            charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n            /* tslint:enable */\n        }\n    }\n}\n//# sourceMappingURL=lexer.js.map"]},"metadata":{},"sourceType":"module"}