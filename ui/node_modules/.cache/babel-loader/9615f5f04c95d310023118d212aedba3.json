{"ast":null,"code":"import { has, isString, isUndefined } from \"../utils/utils\";\nimport { Lexer } from \"./lexer_public\";\nimport { augmentTokenTypes, tokenStructuredMatcher } from \"./tokens\";\nexport function tokenLabel(tokType) {\n  if (hasTokenLabel(tokType)) {\n    return tokType.LABEL;\n  } else {\n    return tokType.name;\n  }\n}\nexport function tokenName(tokType) {\n  return tokType.name;\n}\nexport function hasTokenLabel(obj) {\n  return isString(obj.LABEL) && obj.LABEL !== \"\";\n}\nvar PARENT = \"parent\";\nvar CATEGORIES = \"categories\";\nvar LABEL = \"label\";\nvar GROUP = \"group\";\nvar PUSH_MODE = \"push_mode\";\nvar POP_MODE = \"pop_mode\";\nvar LONGER_ALT = \"longer_alt\";\nvar LINE_BREAKS = \"line_breaks\";\nvar START_CHARS_HINT = \"start_chars_hint\";\nexport function createToken(config) {\n  return createTokenInternal(config);\n}\n\nfunction createTokenInternal(config) {\n  var pattern = config.pattern;\n  var tokenType = {};\n  tokenType.name = config.name;\n\n  if (!isUndefined(pattern)) {\n    tokenType.PATTERN = pattern;\n  }\n\n  if (has(config, PARENT)) {\n    throw \"The parent property is no longer supported.\\n\" + \"See: https://github.com/SAP/chevrotain/issues/564#issuecomment-349062346 for details.\";\n  }\n\n  if (has(config, CATEGORIES)) {\n    // casting to ANY as this will be fixed inside `augmentTokenTypes``\n    tokenType.CATEGORIES = config[CATEGORIES];\n  }\n\n  augmentTokenTypes([tokenType]);\n\n  if (has(config, LABEL)) {\n    tokenType.LABEL = config[LABEL];\n  }\n\n  if (has(config, GROUP)) {\n    tokenType.GROUP = config[GROUP];\n  }\n\n  if (has(config, POP_MODE)) {\n    tokenType.POP_MODE = config[POP_MODE];\n  }\n\n  if (has(config, PUSH_MODE)) {\n    tokenType.PUSH_MODE = config[PUSH_MODE];\n  }\n\n  if (has(config, LONGER_ALT)) {\n    tokenType.LONGER_ALT = config[LONGER_ALT];\n  }\n\n  if (has(config, LINE_BREAKS)) {\n    tokenType.LINE_BREAKS = config[LINE_BREAKS];\n  }\n\n  if (has(config, START_CHARS_HINT)) {\n    tokenType.START_CHARS_HINT = config[START_CHARS_HINT];\n  }\n\n  return tokenType;\n}\n\nexport var EOF = createToken({\n  name: \"EOF\",\n  pattern: Lexer.NA\n});\naugmentTokenTypes([EOF]);\nexport function createTokenInstance(tokType, image, startOffset, endOffset, startLine, endLine, startColumn, endColumn) {\n  return {\n    image: image,\n    startOffset: startOffset,\n    endOffset: endOffset,\n    startLine: startLine,\n    endLine: endLine,\n    startColumn: startColumn,\n    endColumn: endColumn,\n    tokenTypeIdx: tokType.tokenTypeIdx,\n    tokenType: tokType\n  };\n}\nexport function tokenMatcher(token, tokType) {\n  return tokenStructuredMatcher(token, tokType);\n}","map":{"version":3,"sources":["../../../src/scan/tokens_public.ts"],"names":[],"mappings":"AAAA,SAAS,GAAT,EAAc,QAAd,EAAwB,WAAxB,QAA2C,gBAA3C;AACA,SAAS,KAAT,QAAsB,gBAAtB;AACA,SAAS,iBAAT,EAA4B,sBAA5B,QAA0D,UAA1D;AAGA,OAAM,SAAU,UAAV,CAAqB,OAArB,EAAuC;AAC3C,MAAI,aAAa,CAAC,OAAD,CAAjB,EAA4B;AAC1B,WAAO,OAAO,CAAC,KAAf;AACD,GAFD,MAEO;AACL,WAAO,OAAO,CAAC,IAAf;AACD;AACF;AAED,OAAM,SAAU,SAAV,CAAoB,OAApB,EAAsC;AAC1C,SAAO,OAAO,CAAC,IAAf;AACD;AAED,OAAM,SAAU,aAAV,CAAwB,GAAxB,EAAsC;AAC1C,SAAO,QAAQ,CAAO,GAAI,CAAC,KAAZ,CAAR,IAAoC,GAAI,CAAC,KAAL,KAAe,EAA1D;AACD;AAED,IAAM,MAAM,GAAG,QAAf;AACA,IAAM,UAAU,GAAG,YAAnB;AACA,IAAM,KAAK,GAAG,OAAd;AACA,IAAM,KAAK,GAAG,OAAd;AACA,IAAM,SAAS,GAAG,WAAlB;AACA,IAAM,QAAQ,GAAG,UAAjB;AACA,IAAM,UAAU,GAAG,YAAnB;AACA,IAAM,WAAW,GAAG,aAApB;AACA,IAAM,gBAAgB,GAAG,kBAAzB;AAEA,OAAM,SAAU,WAAV,CAAsB,MAAtB,EAA0C;AAC9C,SAAO,mBAAmB,CAAC,MAAD,CAA1B;AACD;;AAED,SAAS,mBAAT,CAA6B,MAA7B,EAAiD;AAC/C,MAAI,OAAO,GAAG,MAAM,CAAC,OAArB;AAEA,MAAI,SAAS,GAAmB,EAAhC;AACA,EAAA,SAAS,CAAC,IAAV,GAAiB,MAAM,CAAC,IAAxB;;AAEA,MAAI,CAAC,WAAW,CAAC,OAAD,CAAhB,EAA2B;AACzB,IAAA,SAAS,CAAC,OAAV,GAAoB,OAApB;AACD;;AAED,MAAI,GAAG,CAAC,MAAD,EAAS,MAAT,CAAP,EAAyB;AACvB,UACE,kDACA,uFAFF;AAID;;AAED,MAAI,GAAG,CAAC,MAAD,EAAS,UAAT,CAAP,EAA6B;AAC3B;AACA,IAAA,SAAS,CAAC,UAAV,GAA4B,MAAM,CAAC,UAAD,CAAlC;AACD;;AAED,EAAA,iBAAiB,CAAC,CAAC,SAAD,CAAD,CAAjB;;AAEA,MAAI,GAAG,CAAC,MAAD,EAAS,KAAT,CAAP,EAAwB;AACtB,IAAA,SAAS,CAAC,KAAV,GAAkB,MAAM,CAAC,KAAD,CAAxB;AACD;;AAED,MAAI,GAAG,CAAC,MAAD,EAAS,KAAT,CAAP,EAAwB;AACtB,IAAA,SAAS,CAAC,KAAV,GAAkB,MAAM,CAAC,KAAD,CAAxB;AACD;;AAED,MAAI,GAAG,CAAC,MAAD,EAAS,QAAT,CAAP,EAA2B;AACzB,IAAA,SAAS,CAAC,QAAV,GAAqB,MAAM,CAAC,QAAD,CAA3B;AACD;;AAED,MAAI,GAAG,CAAC,MAAD,EAAS,SAAT,CAAP,EAA4B;AAC1B,IAAA,SAAS,CAAC,SAAV,GAAsB,MAAM,CAAC,SAAD,CAA5B;AACD;;AAED,MAAI,GAAG,CAAC,MAAD,EAAS,UAAT,CAAP,EAA6B;AAC3B,IAAA,SAAS,CAAC,UAAV,GAAuB,MAAM,CAAC,UAAD,CAA7B;AACD;;AAED,MAAI,GAAG,CAAC,MAAD,EAAS,WAAT,CAAP,EAA8B;AAC5B,IAAA,SAAS,CAAC,WAAV,GAAwB,MAAM,CAAC,WAAD,CAA9B;AACD;;AAED,MAAI,GAAG,CAAC,MAAD,EAAS,gBAAT,CAAP,EAAmC;AACjC,IAAA,SAAS,CAAC,gBAAV,GAA6B,MAAM,CAAC,gBAAD,CAAnC;AACD;;AAED,SAAO,SAAP;AACD;;AAED,OAAO,IAAM,GAAG,GAAG,WAAW,CAAC;AAAE,EAAA,IAAI,EAAE,KAAR;AAAe,EAAA,OAAO,EAAE,KAAK,CAAC;AAA9B,CAAD,CAAvB;AACP,iBAAiB,CAAC,CAAC,GAAD,CAAD,CAAjB;AAEA,OAAM,SAAU,mBAAV,CACJ,OADI,EAEJ,KAFI,EAGJ,WAHI,EAIJ,SAJI,EAKJ,SALI,EAMJ,OANI,EAOJ,WAPI,EAQJ,SARI,EAQa;AAEjB,SAAO;AACL,IAAA,KAAK,EAAA,KADA;AAEL,IAAA,WAAW,EAAA,WAFN;AAGL,IAAA,SAAS,EAAA,SAHJ;AAIL,IAAA,SAAS,EAAA,SAJJ;AAKL,IAAA,OAAO,EAAA,OALF;AAML,IAAA,WAAW,EAAA,WANN;AAOL,IAAA,SAAS,EAAA,SAPJ;AAQL,IAAA,YAAY,EAAQ,OAAQ,CAAC,YARxB;AASL,IAAA,SAAS,EAAE;AATN,GAAP;AAWD;AAED,OAAM,SAAU,YAAV,CAAuB,KAAvB,EAAsC,OAAtC,EAAwD;AAC5D,SAAO,sBAAsB,CAAC,KAAD,EAAQ,OAAR,CAA7B;AACD","sourceRoot":"","sourcesContent":["import { has, isString, isUndefined } from \"../utils/utils\";\nimport { Lexer } from \"./lexer_public\";\nimport { augmentTokenTypes, tokenStructuredMatcher } from \"./tokens\";\nexport function tokenLabel(tokType) {\n    if (hasTokenLabel(tokType)) {\n        return tokType.LABEL;\n    }\n    else {\n        return tokType.name;\n    }\n}\nexport function tokenName(tokType) {\n    return tokType.name;\n}\nexport function hasTokenLabel(obj) {\n    return isString(obj.LABEL) && obj.LABEL !== \"\";\n}\nvar PARENT = \"parent\";\nvar CATEGORIES = \"categories\";\nvar LABEL = \"label\";\nvar GROUP = \"group\";\nvar PUSH_MODE = \"push_mode\";\nvar POP_MODE = \"pop_mode\";\nvar LONGER_ALT = \"longer_alt\";\nvar LINE_BREAKS = \"line_breaks\";\nvar START_CHARS_HINT = \"start_chars_hint\";\nexport function createToken(config) {\n    return createTokenInternal(config);\n}\nfunction createTokenInternal(config) {\n    var pattern = config.pattern;\n    var tokenType = {};\n    tokenType.name = config.name;\n    if (!isUndefined(pattern)) {\n        tokenType.PATTERN = pattern;\n    }\n    if (has(config, PARENT)) {\n        throw (\"The parent property is no longer supported.\\n\" +\n            \"See: https://github.com/SAP/chevrotain/issues/564#issuecomment-349062346 for details.\");\n    }\n    if (has(config, CATEGORIES)) {\n        // casting to ANY as this will be fixed inside `augmentTokenTypes``\n        tokenType.CATEGORIES = config[CATEGORIES];\n    }\n    augmentTokenTypes([tokenType]);\n    if (has(config, LABEL)) {\n        tokenType.LABEL = config[LABEL];\n    }\n    if (has(config, GROUP)) {\n        tokenType.GROUP = config[GROUP];\n    }\n    if (has(config, POP_MODE)) {\n        tokenType.POP_MODE = config[POP_MODE];\n    }\n    if (has(config, PUSH_MODE)) {\n        tokenType.PUSH_MODE = config[PUSH_MODE];\n    }\n    if (has(config, LONGER_ALT)) {\n        tokenType.LONGER_ALT = config[LONGER_ALT];\n    }\n    if (has(config, LINE_BREAKS)) {\n        tokenType.LINE_BREAKS = config[LINE_BREAKS];\n    }\n    if (has(config, START_CHARS_HINT)) {\n        tokenType.START_CHARS_HINT = config[START_CHARS_HINT];\n    }\n    return tokenType;\n}\nexport var EOF = createToken({ name: \"EOF\", pattern: Lexer.NA });\naugmentTokenTypes([EOF]);\nexport function createTokenInstance(tokType, image, startOffset, endOffset, startLine, endLine, startColumn, endColumn) {\n    return {\n        image: image,\n        startOffset: startOffset,\n        endOffset: endOffset,\n        startLine: startLine,\n        endLine: endLine,\n        startColumn: startColumn,\n        endColumn: endColumn,\n        tokenTypeIdx: tokType.tokenTypeIdx,\n        tokenType: tokType\n    };\n}\nexport function tokenMatcher(token, tokType) {\n    return tokenStructuredMatcher(token, tokType);\n}\n//# sourceMappingURL=tokens_public.js.map"]},"metadata":{},"sourceType":"module"}